{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AST 7939 Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdf18ff9410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = iris.target\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_scaled = StandardScaler().fit(X_train).transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit(X_train).transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build our first neural network. We will use sklearn's MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPClassifier in module sklearn.neural_network._multilayer_perceptron:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : double, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      If early stopping is False, then the training stops when the training\n",
      " |      loss does not improve by more than tol for n_iter_no_change consecutive\n",
      " |      passes over the training set.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22897473\n",
      "Iteration 2, loss = 1.17946500\n",
      "Iteration 3, loss = 1.13225208\n",
      "Iteration 4, loss = 1.08798588\n",
      "Iteration 5, loss = 1.04608248\n",
      "Iteration 6, loss = 1.00658002\n",
      "Iteration 7, loss = 0.96930321\n",
      "Iteration 8, loss = 0.93406316\n",
      "Iteration 9, loss = 0.90028484\n",
      "Iteration 10, loss = 0.86750427\n",
      "Iteration 11, loss = 0.83587758\n",
      "Iteration 12, loss = 0.80565523\n",
      "Iteration 13, loss = 0.77704118\n",
      "Iteration 14, loss = 0.74996988\n",
      "Iteration 15, loss = 0.72432527\n",
      "Iteration 16, loss = 0.69972983\n",
      "Iteration 17, loss = 0.67601840\n",
      "Iteration 18, loss = 0.65329978\n",
      "Iteration 19, loss = 0.63138212\n",
      "Iteration 20, loss = 0.61012130\n",
      "Iteration 21, loss = 0.58965631\n",
      "Iteration 22, loss = 0.57009024\n",
      "Iteration 23, loss = 0.55148502\n",
      "Iteration 24, loss = 0.53393829\n",
      "Iteration 25, loss = 0.51720953\n",
      "Iteration 26, loss = 0.50121006\n",
      "Iteration 27, loss = 0.48580969\n",
      "Iteration 28, loss = 0.47095097\n",
      "Iteration 29, loss = 0.45658959\n",
      "Iteration 30, loss = 0.44272659\n",
      "Iteration 31, loss = 0.42934290\n",
      "Iteration 32, loss = 0.41650292\n",
      "Iteration 33, loss = 0.40420389\n",
      "Iteration 34, loss = 0.39240632\n",
      "Iteration 35, loss = 0.38107381\n",
      "Iteration 36, loss = 0.37010383\n",
      "Iteration 37, loss = 0.35945658\n",
      "Iteration 38, loss = 0.34919066\n",
      "Iteration 39, loss = 0.33927667\n",
      "Iteration 40, loss = 0.32970685\n",
      "Iteration 41, loss = 0.32044199\n",
      "Iteration 42, loss = 0.31145503\n",
      "Iteration 43, loss = 0.30277299\n",
      "Iteration 44, loss = 0.29434910\n",
      "Iteration 45, loss = 0.28616085\n",
      "Iteration 46, loss = 0.27821488\n",
      "Iteration 47, loss = 0.27051159\n",
      "Iteration 48, loss = 0.26304735\n",
      "Iteration 49, loss = 0.25581898\n",
      "Iteration 50, loss = 0.24880460\n",
      "Iteration 51, loss = 0.24200591\n",
      "Iteration 52, loss = 0.23542287\n",
      "Iteration 53, loss = 0.22907248\n",
      "Iteration 54, loss = 0.22297363\n",
      "Iteration 55, loss = 0.21710602\n",
      "Iteration 56, loss = 0.21146046\n",
      "Iteration 57, loss = 0.20603900\n",
      "Iteration 58, loss = 0.20083204\n",
      "Iteration 59, loss = 0.19583904\n",
      "Iteration 60, loss = 0.19102188\n",
      "Iteration 61, loss = 0.18637784\n",
      "Iteration 62, loss = 0.18191215\n",
      "Iteration 63, loss = 0.17761948\n",
      "Iteration 64, loss = 0.17349561\n",
      "Iteration 65, loss = 0.16953941\n",
      "Iteration 66, loss = 0.16574485\n",
      "Iteration 67, loss = 0.16211644\n",
      "Iteration 68, loss = 0.15865199\n",
      "Iteration 69, loss = 0.15533853\n",
      "Iteration 70, loss = 0.15216480\n",
      "Iteration 71, loss = 0.14911550\n",
      "Iteration 72, loss = 0.14618047\n",
      "Iteration 73, loss = 0.14335789\n",
      "Iteration 74, loss = 0.14064719\n",
      "Iteration 75, loss = 0.13804976\n",
      "Iteration 76, loss = 0.13555855\n",
      "Iteration 77, loss = 0.13316855\n",
      "Iteration 78, loss = 0.13087572\n",
      "Iteration 79, loss = 0.12868192\n",
      "Iteration 80, loss = 0.12659487\n",
      "Iteration 81, loss = 0.12459936\n",
      "Iteration 82, loss = 0.12269024\n",
      "Iteration 83, loss = 0.12086666\n",
      "Iteration 84, loss = 0.11912939\n",
      "Iteration 85, loss = 0.11746899\n",
      "Iteration 86, loss = 0.11588095\n",
      "Iteration 87, loss = 0.11436321\n",
      "Iteration 88, loss = 0.11291112\n",
      "Iteration 89, loss = 0.11152334\n",
      "Iteration 90, loss = 0.11019497\n",
      "Iteration 91, loss = 0.10892365\n",
      "Iteration 92, loss = 0.10770533\n",
      "Iteration 93, loss = 0.10653951\n",
      "Iteration 94, loss = 0.10542235\n",
      "Iteration 95, loss = 0.10435447\n",
      "Iteration 96, loss = 0.10333114\n",
      "Iteration 97, loss = 0.10234841\n",
      "Iteration 98, loss = 0.10140445\n",
      "Iteration 99, loss = 0.10049875\n",
      "Iteration 100, loss = 0.09962899\n",
      "Iteration 101, loss = 0.09879662\n",
      "Iteration 102, loss = 0.09800447\n",
      "Iteration 103, loss = 0.09724322\n",
      "Iteration 104, loss = 0.09651332\n",
      "Iteration 105, loss = 0.09581360\n",
      "Iteration 106, loss = 0.09514088\n",
      "Iteration 107, loss = 0.09449401\n",
      "Iteration 108, loss = 0.09387047\n",
      "Iteration 109, loss = 0.09326883\n",
      "Iteration 110, loss = 0.09268860\n",
      "Iteration 111, loss = 0.09212903\n",
      "Iteration 112, loss = 0.09158912\n",
      "Iteration 113, loss = 0.09106688\n",
      "Iteration 114, loss = 0.09056216\n",
      "Iteration 115, loss = 0.09007786\n",
      "Iteration 116, loss = 0.08960983\n",
      "Iteration 117, loss = 0.08915621\n",
      "Iteration 118, loss = 0.08871632\n",
      "Iteration 119, loss = 0.08829013\n",
      "Iteration 120, loss = 0.08787787\n",
      "Iteration 121, loss = 0.08747955\n",
      "Iteration 122, loss = 0.08709204\n",
      "Iteration 123, loss = 0.08671438\n",
      "Iteration 124, loss = 0.08635544\n",
      "Iteration 125, loss = 0.08600673\n",
      "Iteration 126, loss = 0.08566527\n",
      "Iteration 127, loss = 0.08533096\n",
      "Iteration 128, loss = 0.08500389\n",
      "Iteration 129, loss = 0.08468555\n",
      "Iteration 130, loss = 0.08437429\n",
      "Iteration 131, loss = 0.08407887\n",
      "Iteration 132, loss = 0.08379111\n",
      "Iteration 133, loss = 0.08350913\n",
      "Iteration 134, loss = 0.08323242\n",
      "Iteration 135, loss = 0.08296123\n",
      "Iteration 136, loss = 0.08269592\n",
      "Iteration 137, loss = 0.08243811\n",
      "Iteration 138, loss = 0.08218954\n",
      "Iteration 139, loss = 0.08194979\n",
      "Iteration 140, loss = 0.08171956\n",
      "Iteration 141, loss = 0.08149413\n",
      "Iteration 142, loss = 0.08127118\n",
      "Iteration 143, loss = 0.08105100\n",
      "Iteration 144, loss = 0.08083571\n",
      "Iteration 145, loss = 0.08062864\n",
      "Iteration 146, loss = 0.08042526\n",
      "Iteration 147, loss = 0.08022547\n",
      "Iteration 148, loss = 0.08002908\n",
      "Iteration 149, loss = 0.07983808\n",
      "Iteration 150, loss = 0.07966063\n",
      "Iteration 151, loss = 0.07948665\n",
      "Iteration 152, loss = 0.07931258\n",
      "Iteration 153, loss = 0.07914254\n",
      "Iteration 154, loss = 0.07897235\n",
      "Iteration 155, loss = 0.07880121\n",
      "Iteration 156, loss = 0.07863072\n",
      "Iteration 157, loss = 0.07847780\n",
      "Iteration 158, loss = 0.07832058\n",
      "Iteration 159, loss = 0.07817017\n",
      "Iteration 160, loss = 0.07802264\n",
      "Iteration 161, loss = 0.07787939\n",
      "Iteration 162, loss = 0.07773822\n",
      "Iteration 163, loss = 0.07759549\n",
      "Iteration 164, loss = 0.07745575\n",
      "Iteration 165, loss = 0.07731655\n",
      "Iteration 166, loss = 0.07717675\n",
      "Iteration 167, loss = 0.07703870\n",
      "Iteration 168, loss = 0.07692521\n",
      "Iteration 169, loss = 0.07680198\n",
      "Iteration 170, loss = 0.07666566\n",
      "Iteration 171, loss = 0.07654065\n",
      "Iteration 172, loss = 0.07642312\n",
      "Iteration 173, loss = 0.07630982\n",
      "Iteration 174, loss = 0.07619533\n",
      "Iteration 175, loss = 0.07608086\n",
      "Iteration 176, loss = 0.07596445\n",
      "Iteration 177, loss = 0.07584849\n",
      "Iteration 178, loss = 0.07572947\n",
      "Iteration 179, loss = 0.07562779\n",
      "Iteration 180, loss = 0.07552584\n",
      "Iteration 181, loss = 0.07542012\n",
      "Iteration 182, loss = 0.07531104\n",
      "Iteration 183, loss = 0.07521167\n",
      "Iteration 184, loss = 0.07511815\n",
      "Iteration 185, loss = 0.07502399\n",
      "Iteration 186, loss = 0.07492663\n",
      "Iteration 187, loss = 0.07483546\n",
      "Iteration 188, loss = 0.07474904\n",
      "Iteration 189, loss = 0.07466066\n",
      "Iteration 190, loss = 0.07457278\n",
      "Iteration 191, loss = 0.07448186\n",
      "Iteration 192, loss = 0.07440036\n",
      "Iteration 193, loss = 0.07431330\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,100),activation=\"relu\",\n",
    "                      max_iter=1000,random_state=1,verbose=1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred=model.predict(X_test_scaled)\n",
    "print(model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig=plot_confusion_matrix(model, X_test_scaled, y_test,display_labels=[\"Setosa\",\"Versicolor\",\"Virginica\"])\n",
    "fig.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96826712e-05, 5.58582618e-04, 9.99411735e-01],\n",
       "       [4.67674808e-03, 9.91826979e-01, 3.49627262e-03],\n",
       "       [9.98464698e-01, 1.37220172e-03, 1.63100174e-04],\n",
       "       [4.02487097e-05, 1.56964843e-03, 9.98390103e-01],\n",
       "       [9.98117840e-01, 1.69176535e-03, 1.90394457e-04],\n",
       "       [2.42419682e-06, 2.62080541e-05, 9.99971368e-01],\n",
       "       [9.98103316e-01, 1.71108518e-03, 1.85598638e-04],\n",
       "       [3.21786920e-03, 8.70071557e-01, 1.26710574e-01],\n",
       "       [3.03947768e-03, 9.12867415e-01, 8.40931074e-02],\n",
       "       [2.62300726e-03, 9.92711501e-01, 4.66549152e-03],\n",
       "       [1.93714461e-03, 2.66602509e-01, 7.31460347e-01],\n",
       "       [2.84983940e-03, 9.39308349e-01, 5.78418115e-02],\n",
       "       [2.26456361e-03, 9.84891619e-01, 1.28438176e-02],\n",
       "       [3.04310427e-03, 9.11325677e-01, 8.56312189e-02],\n",
       "       [2.83396267e-03, 9.41402066e-01, 5.57639709e-02],\n",
       "       [9.98917721e-01, 9.56609733e-04, 1.25669120e-04],\n",
       "       [2.84983940e-03, 9.39308349e-01, 5.78418115e-02],\n",
       "       [2.26653366e-03, 9.92083972e-01, 5.64949444e-03],\n",
       "       [9.97684254e-01, 2.09891874e-03, 2.16827046e-04],\n",
       "       [9.96953048e-01, 2.79213507e-03, 2.54816881e-04],\n",
       "       [4.93246347e-04, 2.94142705e-02, 9.70092483e-01],\n",
       "       [2.84983940e-03, 9.39308349e-01, 5.78418115e-02],\n",
       "       [9.94973537e-01, 4.63120225e-03, 3.95260297e-04],\n",
       "       [9.98464698e-01, 1.37220172e-03, 1.63100174e-04],\n",
       "       [2.00643448e-03, 2.31163928e-01, 7.66829638e-01],\n",
       "       [9.99227987e-01, 6.81431003e-04, 9.05818042e-05],\n",
       "       [9.86785424e-01, 1.24481400e-02, 7.66435892e-04],\n",
       "       [2.14695819e-03, 9.91720209e-01, 6.13283232e-03],\n",
       "       [2.96982863e-02, 9.65198449e-01, 5.10326497e-03],\n",
       "       [9.93914575e-01, 5.65253850e-03, 4.32886209e-04],\n",
       "       [3.12791374e-04, 2.06569808e-02, 9.79030228e-01],\n",
       "       [2.84983940e-03, 9.39308349e-01, 5.78418115e-02],\n",
       "       [9.98117840e-01, 1.69176535e-03, 1.90394457e-04],\n",
       "       [1.60276978e-03, 1.70694181e-01, 8.27703050e-01],\n",
       "       [2.73208681e-05, 6.09521219e-04, 9.99363158e-01],\n",
       "       [2.57471015e-03, 9.91488353e-01, 5.93693683e-03],\n",
       "       [9.95148976e-01, 4.47636930e-03, 3.74654552e-04],\n",
       "       [2.39565079e-03, 3.49472096e-01, 6.48132253e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100) (100, 100) (100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(model.coefs_[0].shape, model.coefs_[1].shape, model.coefs_[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.77035229e-02,  1.79912983e-01, -2.69376812e-01,\n",
       "        -6.64179892e-02, -4.07818179e-02, -2.73692186e-01,\n",
       "        -2.20854359e-01, -1.85376873e-02,  4.06766635e-02,\n",
       "         7.70989385e-02, -5.63063331e-02,  1.21759656e-01,\n",
       "         1.10468866e-02,  2.66045293e-01, -1.93707553e-01,\n",
       "         1.68877628e-01, -1.14943524e-03,  6.52204001e-02,\n",
       "        -2.17006201e-01, -2.24922974e-01,  3.95419546e-02,\n",
       "         2.01778485e-01, -1.73994834e-01,  1.75892283e-02,\n",
       "         2.82931605e-01,  2.68454078e-01, -2.61530483e-01,\n",
       "        -2.39325161e-01, -1.25654863e-01,  2.45026380e-01,\n",
       "        -2.83244862e-01, -1.94964423e-02,  2.72843463e-01,\n",
       "         3.43801319e-02,  1.02442323e-01, -1.61383018e-01,\n",
       "         2.10371745e-01,  2.14032083e-01, -3.51489736e-01,\n",
       "         1.27694018e-01,  3.46020276e-01,  9.50938604e-02,\n",
       "        -1.04466381e-01,  3.62653720e-02, -2.11061730e-01,\n",
       "        -6.93057764e-02,  7.46248874e-02, -1.07171368e-01,\n",
       "        -8.46621079e-02, -2.40982100e-01, -3.11881004e-01,\n",
       "         1.42243415e-01, -2.18946430e-01, -1.61641211e-01,\n",
       "        -3.53064858e-02, -2.67858108e-01, -2.14816251e-02,\n",
       "        -2.10594281e-01,  1.24019976e-01,  1.61945166e-01,\n",
       "        -2.32451357e-01, -1.01481015e-01,  1.44121655e-01,\n",
       "         2.98771230e-02, -2.90424289e-01, -6.08731749e-02,\n",
       "         4.22666063e-02,  3.75464480e-06,  3.53508754e-01,\n",
       "         1.39001976e-01,  2.94451404e-01, -1.48101371e-01,\n",
       "        -2.32940968e-01,  1.51671407e-01, -1.53873992e-02,\n",
       "        -2.12218954e-01,  2.75801508e-01, -8.08328230e-02,\n",
       "         3.00326635e-02,  8.96365775e-02,  1.86809014e-01,\n",
       "         7.96451184e-03,  1.88048448e-01, -6.99957868e-02,\n",
       "        -1.85328527e-01,  2.56725609e-01, -3.95351293e-02,\n",
       "         2.17549016e-01,  1.30490033e-01,  1.19160926e-01,\n",
       "        -2.06725719e-01,  1.83099125e-01, -1.93259482e-02,\n",
       "         1.07164742e-01,  5.61952811e-02, -2.91605375e-02,\n",
       "         3.70555450e-01,  7.99403604e-04, -3.01876727e-01,\n",
       "         1.48495559e-01],\n",
       "       [-5.98159632e-02,  7.76926558e-02,  1.66812865e-01,\n",
       "        -4.43126914e-02,  2.95723964e-01, -1.41574061e-02,\n",
       "        -3.01342031e-01,  2.56536781e-01,  1.62849912e-01,\n",
       "         2.95299113e-01, -1.74373354e-01, -1.48074361e-01,\n",
       "         3.28706259e-01,  1.68349129e-01, -1.75488059e-01,\n",
       "         1.96940110e-01,  2.68477492e-02,  1.91826456e-01,\n",
       "         5.61792298e-02, -2.59241416e-01, -1.01039025e-01,\n",
       "        -2.53270419e-01, -3.11512597e-01, -1.92318828e-01,\n",
       "         2.62115600e-01,  8.29487725e-02, -3.21426570e-02,\n",
       "         1.59771604e-01, -1.47198693e-01, -4.67745790e-02,\n",
       "        -4.52482787e-02,  2.29908877e-01,  7.44164380e-02,\n",
       "        -2.14311242e-01,  1.51539880e-01, -2.00405681e-01,\n",
       "         2.45383813e-01, -1.32189927e-02,  5.72393469e-02,\n",
       "         1.23826462e-01,  1.11483418e-01, -2.01246219e-01,\n",
       "        -2.11907247e-01, -6.42194916e-02, -2.44785287e-01,\n",
       "        -2.37169813e-01, -3.21437091e-02,  2.17588297e-01,\n",
       "         4.25029029e-02, -2.99389625e-01, -2.85688988e-01,\n",
       "         2.82658695e-01, -4.48153148e-02, -1.88272401e-01,\n",
       "        -1.37643316e-01,  6.13099805e-02, -1.97364716e-01,\n",
       "         3.23147666e-03,  2.99786898e-01,  2.18652377e-01,\n",
       "        -1.82043758e-01, -5.99005036e-02,  1.07772515e-01,\n",
       "         2.38807792e-01, -2.36765683e-01, -3.09208892e-01,\n",
       "        -2.30574973e-01, -2.58868617e-06,  1.53017464e-01,\n",
       "         1.17645710e-01, -6.01070317e-03,  2.99969548e-01,\n",
       "        -1.68096677e-02, -1.04192658e-01,  4.99186373e-02,\n",
       "         7.46390052e-02,  1.35541154e-01, -1.19698089e-01,\n",
       "        -2.96216087e-01, -8.45642571e-02,  4.02452252e-02,\n",
       "        -1.84206133e-01,  1.82579123e-01, -2.04577902e-01,\n",
       "        -1.89434707e-01,  2.06475551e-01, -1.49067107e-01,\n",
       "         4.29814168e-02,  4.78593257e-02,  2.61253996e-01,\n",
       "        -1.34469896e-01, -2.43041085e-01,  1.13822669e-01,\n",
       "         1.93244248e-01,  2.84040498e-01,  8.30365081e-02,\n",
       "        -1.45023832e-01, -2.98526011e-02, -9.26763385e-03,\n",
       "         2.96350089e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,) (3,)\n"
     ]
    }
   ],
   "source": [
    "print(model.intercepts_[0].shape, model.intercepts_[1].shape, model.intercepts_[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2845382 ,  0.08187597,  0.22488755,  0.16163273, -0.00568267,\n",
       "        0.0019831 ,  0.06848635,  0.0665683 ,  0.30619666,  0.28934678,\n",
       "       -0.0492854 ,  0.33359282, -0.04823138, -0.11599276, -0.21275853,\n",
       "        0.03528339, -0.23209456,  0.33149223,  0.22226608, -0.15600645,\n",
       "       -0.15706789, -0.10857822, -0.11492893,  0.25015997, -0.06293935,\n",
       "        0.17996933,  0.03668641,  0.26157016,  0.24365538,  0.27335874,\n",
       "       -0.00193611,  0.12881703,  0.25165281, -0.1218419 , -0.04165124,\n",
       "        0.07653412, -0.1260693 ,  0.13807613, -0.0254531 ,  0.1969036 ,\n",
       "       -0.08744901,  0.2435591 ,  0.03906148, -0.15327757,  0.18915975,\n",
       "        0.11100622, -0.21638579, -0.06128099,  0.18349337,  0.27616406,\n",
       "       -0.16693658,  0.19370081, -0.02166931,  0.28098367,  0.14994267,\n",
       "        0.24602814,  0.12804068,  0.04446735, -0.05927085, -0.00722851,\n",
       "        0.22604677,  0.20632003,  0.13495283,  0.08143851,  0.09588123,\n",
       "       -0.06048578,  0.04647329, -0.02382964, -0.09945498, -0.03473611,\n",
       "       -0.06054568, -0.08447893,  0.05101754,  0.07934852,  0.33576396,\n",
       "        0.18720611, -0.10265446, -0.04678838, -0.03133184,  0.22977801,\n",
       "        0.2862313 ,  0.3153149 ,  0.16046252, -0.11341987, -0.07418552,\n",
       "        0.28411007, -0.02668147,  0.26767986,  0.14436103,  0.20598044,\n",
       "        0.00795334,  0.15211857, -0.00626255, -0.03692323, -0.03978616,\n",
       "       -0.20944923, -0.09974141, -0.2039113 ,  0.33126659, -0.08964336])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercepts_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training Loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlRUlEQVR4nO3deXxddZ3/8dfn3qxNs7RNuq/QjRYKpWnZoYBCQaUqI1AFRXGYEXF3FMd5OKiPUXH7jc7gwgiyDKII6FRBFpWtbG0KpXShC91IKemeNE2b9fP7456US8hNbtLcnHtz38/H4zzuueee5dOT27xzzvec7zF3R0REpDORsAsQEZH0pZAQEZGEFBIiIpKQQkJERBJSSIiISEI5YRfQU+Xl5T5x4sSwyxARySjLly/f7e4VPV0u40Ji4sSJVFVVhV2GiEhGMbOtvVlOp5tERCQhhYSIiCSkkBARkYQUEiIikpBCQkREElJIiIhIQgoJERFJKGtCYt2bB/juQ2upb2wJuxQRkYyRNSHx+t4GfvnUJtbuqAu7FBGRjJE1ITFzTAkAq7fXhlyJiEjmSFlImNltZrbTzFYl+PwjZrbSzF4xs2fN7MRU1QIwsqSAoUV5rH5DRxIiIslK5ZHE7cCCLj7fDJzj7icA3wZuSWEtmBkzR5coJEREeiBlIeHuTwF7u/j8WXffF7x9HhibqlrazRhdwoadB2hqaUv1pkREBoR0aZO4BvhLog/N7FozqzKzql27dvV6IzNHl9Lc6qyvOdDrdYiIZJPQQ8LMziUWEl9NNI+73+Lule5eWVHR4+7Qj5g5OtZ4vUannEREkhJqSJjZLOBXwEJ335Pq7U0aVsSgvCir39AVTiIiyQgtJMxsPPAAcJW7r++PbUYixnGj1HgtIpKslD2ZzszuAeYD5WZWDfw7kAvg7r8AvgEMA35mZgAt7l6ZqnrazRxdwv3Lq2lrcyIRS/XmREQyWspCwt0XdfP5J4FPpmr7icwcXcKdz7WyZc9BjqkY3N+bFxHJKKE3XPe3maNLAXTKSUQkCVkXElNGDCY3agoJEZEkZF1I5OdEmTK8WFc4iYgkIetCAmLtEmveqMPdwy5FRCStZW1I7DnYRE1dY9iliIiktewMiTHtjdc65SQi0pWsDIkZo0qIGLz8+v6wSxERSWtZGRJF+TlMHVHMSwoJEZEuZWVIAMweX8bLr++nrU2N1yIiiWRtSJw0roy6wy1s3nMw7FJERNJWFofEEABWbNsfbiEiImksa0Ni8vDBFOVFWaF2CRGRhLI2JKIRY9bYMoWEiEgXsjYkAE4aX8baHXUcbm4NuxQRkbSU3SExroyWNtdNdSIiCWR1SMweVwbAS2q8FhHpVFaHxPCSAkaXFqhdQkQkgawOCYi1SygkREQ6p5AYV0b1vkPsrlePsCIiHSkkdFOdiEhCWR8SJ4wpJRoxXty2L+xSRETSTtaHRGFelOPHlFK1RSEhItJR1ocEwLyJQ1jx+n7dVCci0oFCApg3aRhNrW16CJGISAcKCWDuxFjj9bIte0OuREQkvaQsJMzsNjPbaWarEnxuZvZTM9toZivN7ORU1dKdskF5TB9ZzAubFRIiIvFSeSRxO7Cgi88vAqYEw7XAz1NYS7fmThzK8q37aGltC7MMEZG0krKQcPengK7+NF8I3OkxzwNlZjYqVfV0Z96koTQ0tbL6jbqwShARSTthtkmMAV6Pe18dTHsHM7vWzKrMrGrXrl0pKWbepKGA2iVEROJlRMO1u9/i7pXuXllRUZGSbYwoKWDisEFqlxARiRNmSGwHxsW9HxtMC83ciUNZtmUvbW0eZhkiImkjzJBYDHw0uMrpVKDW3XeEWA/zJg1lf0MzG3fVh1mGiEjayEnVis3sHmA+UG5m1cC/A7kA7v4L4CHgYmAj0AB8PFW1JOuUScMAeGHzXqaOKA65GhGR8KUsJNx9UTefO/DpVG2/N8YNLWRkSQEvbNrDVadOCLscEZHQZUTDdX8xM04/dhjPvrZH7RIiIigk3uGMyeXsPdjEmh26X0JERCHRwZlTygF4ZuPukCsREQmfQqKDESUFTB0xmCUKCRERhURnzphcztLNe/V8CRHJegqJTpw1pZzGljaWb9XT6kQkuykkOnHKpGHkRo2nN+iUk4hkN4VEJ4ryc5g9fghLNqamM0ERkUyhkEjgzMnlrH6jjr0Hm8IuRUQkNAqJBM6cUo47PPuaTjmJSPZSSCQwa0wpxQU5LFG7hIhkMYVEAjnRCKcdM4ynN+wm1s2UiEj2UUh0Yf604Wzff4iNO9V1uIhkJ4VEF+ZPiz0F7/F1O0OuREQkHAqJLowuK2TaiGKeWKdLYUUkOykkujF/egXLtuylvrEl7FJERPqdQqIb86cOp7nV1SusiGQlhUQ3KicOYXB+Dk+oXUJEspBCohu50QhnTi7niXW7dCmsiGQdhUQSzp1ewY7aw6yrORB2KSIi/UohkYRzpg4H4PFXdZWTiGQXhUQSRpYWcNyoErVLiEjWUUgk6dxpFVRt3UdtQ3PYpYiI9JsehYSZRcysJFXFpLN3zRhBa5vz93U1YZciItJvug0JM/uNmZWYWRGwClhjZv+S+tLSy0ljyxhenM+jqxUSIpI9kjmSmOHudcD7gb8Ak4CrUllUOopEjHfPGMET63ZxuLk17HJERPpFMiGRa2a5xEJisbs3A0ndMGBmC8xsnZltNLMbOvl8vJk9bmYvmdlKM7u4R9X3swtnjuRQc6ueMSEiWSOZkPglsAUoAp4yswlAXXcLmVkUuBm4CJgBLDKzGR1m+zfgXnefDVwB/Cz50vvfqccMo7ggh0dWvxl2KSIi/aLbkHD3n7r7GHe/2GO2Aucmse55wEZ33+TuTcBvgYUdVw+0N4SXAm/0oPZ+l5cT4bzpw/nr2hpaWtvCLkdEJOWSabj+XNBwbWZ2q5m9CJyXxLrHAK/Hva8OpsW7EbjSzKqBh4DPJKjhWjOrMrOqXbvCvaHtwpkj2dfQTNXWfaHWISLSH5I53fSJoOH6AmAIsUbr7/XR9hcBt7v7WOBi4C4ze0dN7n6Lu1e6e2VFRUUfbbp3zplaQV5ORKecRCQrJBMSFrxeDNzl7qvjpnVlOzAu7v3YYFq8a4B7Adz9OaAAKE9i3aEpys/hrMnlPLq6Rh3+iciAl0xILDezR4mFxCNmVgwkc0J+GTDFzCaZWR6xhunFHebZBpwPYGbHEQuJtO8g6cKZI9m+/xCrtnfbfi8iktGSCYlrgBuAue7eAOQBH+9uIXdvAa4HHgHWEruKabWZfcvMLglm+xLwj2b2MnAPcLVnwJ/nF8wcQW7UWPxyxwMjEZGBJae7Gdy9zczGAh82M4An3f1Pyazc3R8i1iAdP+0bceNrgDN6VHEaKBuUxzlTh7P45Te44aLjiEaSOfsmIpJ5krm66XvA54A1wfBZM/tOqgtLdwtPGk1NXSNLN+8NuxQRkZRJ5nTTxcC73f02d78NWAC8N7Vlpb93HTeCQXlRnXISkQEt2V5gy+LGS1NQR8YpzIty4cyRPPTKmzS2qC8nERmYkgmJ7wIvmdntZnYHsBz4j9SWlRkuOXE0tYeaeWq9+nISkYEpmW457gFOBR4A7gdOI9aXU9Y7c0o5QwblsvjltO5NRESk17q9ugnA3XcQd4+DmS0FxqeqqEyRG43wnlmjuG95NQcbWyjKT2p3iohkjN4+vlTXfAYWnjSGw81tPLxK3XSIyMDT25BI+xve+kvlhCFMGDaI+5ZXh12KiEifS3h+xMz+ROdhYMCwlFWUYcyMD80Zyw8fXc/WPQeZMKwo7JJERPpMVyfRf9jLz7LOpXPG8qPH1nPf8mq+dMG0sMsREekzCUPC3Z/sz0Iy2ajSQs6eUsF9y6v5/LumqpsOERkwetsmIR1cPnccO2oPs2Sj7pkQkYFDIdFHzj9uOEMG5XJv1evdzywikiEUEn0kPyfK+2eP4bHVNew72BR2OSIifSKZXmD/ZGaLOwx3Bc++LuiPIjPFh+aMo6m1jT+uUKd/IjIwJHMksQmoB/4nGOqAA8DU4L0EZowu4cRxZdz9wjY92lREBoRkQuJ0d/+wu/8pGK4k9pS6TwMnp7i+jHPVqRPYuLOe5zfpORMikvmSCYnBZnakn6ZgfHDwViffO3jvrFGUDcrlrue3hF2KiMhRS6ZHui8BS8zsNWJ3W08CrjOzIuCOVBaXiQpyo1xWOY5bl2ympu4wI0rUbCMimSuZrsIfAqYAnyf2GNNp7v6gux909/9MbXmZ6SOnjKfNnXuWbgu7FBGRo5LsJbBzgJnAicBlZvbR1JWU+SYMK+KcqRXcs3Qbza1tYZcjItJryVwCexexvprOBOYGQ2WK68p4V506gZq6Rh5bUxN2KSIivZZMm0QlMMN1TWePzJ82nDFlhdzx7BYuPmFU2OWIiPRKMqebVgEjU13IQBONGFefPpEXNu9l1fbasMsREemVZEKiHFhjZo/E33Wd6sIGgsvnjaMoL8qtSzaHXYqISK8kc7rpxt6u3MwWAD8BosCv3P17ncxzWbANB1529w/3dnvppqQgl8vmjuOu57by1QXTGVmqy2FFJLN0GxK9fa6EmUWBm4F3A9XAMjNb7O5r4uaZAnwNOMPd95nZ8N5sK519/PRJ3PHsFu54bgtfXTA97HJERHok4ekmM1sSvB4ws7q44YCZ1SWx7nnARnff5O5NwG+BhR3m+UfgZnffB+DuO3v3z0hf44cN4oIZI/nNC9toaGoJuxwRkR5JGBLufmbwWuzuJXFDsbuXJLHuMUD8wxWqg2nxpgJTzewZM3s+OD31DmZ2rZlVmVnVrl27kth0evnkWZOoPdTM/curwy5FRKRHkrqZzsyiZjbazMa3D320/Rxid3PPBxYB/2NmZR1ncvdb3L3S3SsrKir6aNP9Z86EIZw4roxfLdlMi26uE5EMkszNdJ8BaoDHgAeD4c9JrHs7MC7u/dhgWrxqYLG7N7v7ZmA9sdAYUMyMT51zDFv3NPDgKzvCLkdEJGnJHEm099c0091PCIZZSSy3DJhiZpPMLA+4Auh46ewfiR1FYGblxE4/bUq2+ExywYyRTBk+mJsf30hbm+5LFJHMkExIvA70+G4wd28BrgceAdYC97r7ajP7lpldEsz2CLDHzNYAjwP/4u57erqtTBCJGNefN5n1NfU8uubNsMsREUmKddfbhpndCkwjdpqpsX26u/84taV1rrKy0quqqsLY9FFraW3jXT9+kqL8HP78mTMxs7BLEpEsYWbL3b3H/e4lcySxjVh7RB5QHDdID+VEI1w3fzKr36jjiXWZd5WWiGSfZG6m+2Z/FJIt3j97DD/52wZ++vcNzJ9WoaMJEUlrXd1M95/B65/i+2xS301HJy8nwqfmH8tL2/bz+LoBd++giAwwXR1J3BW8/rA/Cskml88dx6+e3sRNf1nHOVOHE43oaEJE0lNXd1wvD16f7GzovxIHntxohC9fOI11NQd44EXdhS0i6SuZm+mmmNl9ZrbGzDa1D/1R3EB28fGjmDW2lB8/tp7Dza1hlyMi0qlkrm76NfBzoAU4F7gT+N9UFpUNIhHjhoums6P2MHc+tyXsckREOpVMSBS6+9+I3VOx1d1vBN6T2rKyw+nHlnPO1Apufvw19jc0hV2OiMg7JBMSjWYWATaY2fVm9gFgcIrryho3XDSdA4eb+X+PrQ+7FBGRd0i276ZBwGeBOcCVwMdSWVQ2OW5UCR85ZQJ3Pb+VtTuSeUyHiEj/6TIkgqfLXe7u9e5e7e4fd/dL3f35fqovK3zpgqmUFuby74tX0103KSIi/amrm+ly3L0VOLMf68lKZYPy+PKF01i6eS9/WqmuxEUkfXR1JLE0eH0puMv6KjP7YPvQH8Vlkyvmjuf4MSV858G1HGzUY05FJD0k0yZRAOwBzgPeC7wveJU+FI0Y37xkJm/WHeYnf9sQdjkiIkDX3XIMN7MvAqsAB+L7jtCJ8xSYM2Eoi+aN49Ylm7nkxNEcP6Y07JJEJMt1dSQRJXap62BiXYMP7jBICtyw4DiGDMrjaw+8QqueYCciIevqSGKHu3+r3yoRAEoH5XLjJTO4/jcvcfuzW7jmzElhlyQiWayrIwl1TRqS95wwivOmD+dHj66jel9D2OWISBbrKiTO77cq5G3MjG+//3gAvvbAK7p3QkRC01VX4Xv7sxB5uzFlhfzrxcfx9Ibd3P3CtrDLEZEslcwlsBKSj5wynrOmlPOdh9aydc/BsMsRkSykkEhjZsZNl84iGjH+5fcrdbWTiPQ7hUSaG11WyI3vm8nSLXu5dYme9SQi/UshkQE+ePIYLpw5gh88so5XqmvDLkdEsohCIgO0n3aqGJzP9fe8yIHDzWGXJCJZIqUhYWYLzGydmW00sxu6mO9SM3Mzq0xlPZmsbFAeP1k0m+p9h/j6H1bpslgR6RcpC4ngWRQ3AxcBM4BFZjajk/mKiT3Y6IVU1TJQzJ04lC+8awqLX36De6teD7scEckCqTySmAdsdPdN7t4E/BZY2Ml83wZuAg6nsJYB41PzJ3P6scP4xv+tZtV2tU+ISGqlMiTGAPF/7lYH044ws5OBce7+YFcrMrNrzazKzKp27drV95VmkGjE+Omi2QwtyuOf7lrOnvrGsEsSkQEstIZrM4sAPwa+1N287n6Lu1e6e2VFRUXqi0tz5YPz+eVVc9hV38j1v3mJlta2sEsSkQEqlSGxHRgX935sMK1dMXA88ISZbQFOBRar8To5s8aW8Z0PnMBzm/bwnYdeDbscERmguuoq/GgtA6aY2SRi4XAF8OH2D929Fihvf29mTwBfdveqFNY0oPzDnLGs2l7Lbc9sZsqIwSyaNz7skkRkgEnZkYS7twDXA48Aa4F73X21mX3LzC5J1Xazzb+95zjOmVrBv/1xFUs27A67HBEZYCzTrrevrKz0qiodbMQ7cLiZD/3iObbvO8T9153O1BHFYZckImnGzJa7e49P5+uO6wGguCCXW6+eS0FelI//ehk7D+hqYhHpGwqJAWJMWSG3fqySfQ1NfOy2ZdQeUtcdInL0FBIDyKyxZfziyjls3HmAf7yjisPNrWGXJCIZTiExwJw9tYIfX3YSy7bu1T0UInLUFBID0PtOHM03L5nJX9fW8IV7X1ZQiEivpfI+CQnRR0+byMHGVm56+FUM+PFlJ5IT1d8EItIzCokB7FPzj8Vxvv/wOszgRx9SUIhIzygkBrjr5k8G4PsPrwMUFCLSMwqJLHDd/Mm4ww8eUVCISM8oJLLEp8+djFnsiOJgYyv//eHZFORGwy5LRNKc/pzMItfNn8y3Fs7kb6/WcNWtL1DboBvuRKRrCoks89HTJvJfi2az4vX9XPbL56ipUxceIpKYQiILvXfWaG7/+Dyq9zXwwZ89y6Zd9WGXJCJpSiGRpc6YXM5vrz2Nw82tXPrzZ3l+056wSxKRNKSQyGInjC3l/k+dzpCiPK781Qv8btm2sEsSkTSjkMhyE8uL+MN1Z3DascP46v2v8O0/r6G1LbOeMSIiqaOQEEoLc/n11XO5+vSJ3LpkM9fcsYy6w7rySUQUEhLIiUa48ZKZ/McHjmfJht28/7+fYe2OurDLEpGQKSTkbT5yygTu/uQp1De28P6bn+HeZa+TaY+4FZG+o5CQdzjlmGE8+NmzqJw4hK/cv5Iv/34lDU0tYZclIiFQSEinKorzufMTp/C586fwwEvVLPzvZ1j35oGwyxKRfqaQkISiEeML757KnZ+Yx76GJt73X0v45ZOv6eonkSyikJBunTWlgoc/fzbnTq/gu395lStueY5texrCLktE+oFCQpJSPjifX1w5hx996ERe3XGABT95irtf2KpGbZEBTiEhSTMzLp0zlke+cDazx5fx9T+s4rJfPserb+pSWZGBKqUhYWYLzGydmW00sxs6+fyLZrbGzFaa2d/MbEIq65G+MbqskLs+cQo3XXoCG3fW856fLuE7D63lYKOugBIZaFIWEmYWBW4GLgJmAIvMbEaH2V4CKt19FnAf8P1U1SN9KxIxLp87nr9/aT6XVY7llqc2cf6PnuTPK9/QKSiRASSVRxLzgI3uvsndm4DfAgvjZ3D3x929vQX0eWBsCuuRFBhSlMd3PzjrSEeB1//mJT7ws2d5Qb3KigwIqQyJMcDrce+rg2mJXAP8pbMPzOxaM6sys6pdu3b1YYnSV+ZMGMKfrj+Dmy49gR21h7j8lue55vZlurdCJMOlRcO1mV0JVAI/6Oxzd7/F3SvdvbKioqJ/i5Ok5UQjXD53PE98+Vy+smAaS7fs5aKfPMUXf7eCjTsVFiKZKCeF694OjIt7PzaY9jZm9i7g68A57t6YwnqknxTmRblu/mQWzR3Pz57YyP8+v40/rNjOxceP4rpzj2Xm6NKwSxSRJFmqGhnNLAdYD5xPLByWAR9299Vx88wm1mC9wN03JLPeyspKr6qqSkHFkip76hu57ZnN3PnsVg40tnDe9OFce/YxnDJpKGYWdnkiWcHMlrt7ZY+XS+WVKGZ2MfCfQBS4zd3/w8y+BVS5+2Iz+ytwArAjWGSbu1/S1ToVEpmr9lAzdz67hdue2cy+hmamjyzm6tMnsvCkMRTmRcMuT2RAS8uQSAWFROY71NTK4pe38+tntvDqmwcoLczlirnjuGzuOI6tGBx2eSIDkkJCMo67s3TzXm5/dguPrqmhtc05eXwZ/zBnHO+ZNYrSwtywSxQZMBQSktF21h3mjyu28/uqajbsrCcvJ8K7Z4zgvSeMYv604TodJXKUFBIyILg7r2yv5fdV1Tz4yg72HmyiMDfKedOHc9EJIzl32nCK8lN5UZ7IwKSQkAGnpbWNpZv38tCqHTy8qobd9Y3kRSPMmzSU+dMqmD9tOMdWFOkKKZEkKCRkQGttc5Zt2cvfX93JE+t2sr6mHoCxQwo5d9pwzplawdxJQ9WOIZKAQkKySvW+Bp5cv4vHX93FMxt3c6i5FTM4bmQJ8yYNZd6kocydOJSK4vywSxVJCwoJyVqNLa28uHU/y7bsZenmvSzfuo9Dza0AHFNRxEnjyjhhTCmzxpYyY1SpGsElK/U2JNQCKBkvPyfKaccO47RjhwHQ3NrGqu21LN0cC42nN+zmgRdjPcJEDKYML+aEsaXMGFXC1BHFTB0xmIrifLVtiHRCRxIy4Lk7NXWNvLK9NjZU7+eV7bXsrm86Mk9pYS5TRwxmyohiJlcMZmL5ICYMK2LskELyc3TkIZlPRxIiCZgZI0sLGFlawLtnjABiwbG7vokNNQdYX3OA9Tvr2VBzgAdX7qD2UHPcsjC6tJAJwwYxYdggxg8tYvzQQYwqK2BUaQHDiwuIRnQEIgOXQkKykplRUZxPRXE+p08uPzK9PTy27T3I1j0NwXCQrXsbeHR1DXsONr1tPdGIMbw4n5GlBYwuLWRkaQEjSvIpHxwbhg3Oo2JwPkOK8siNpkXP/CI9opAQiRMfHnMmDH3H5wcON/P63kPU1B3mjdpDvFl7mB21h9lRe4i1b9bx91d3Hmk072jIoFyGDc6nfHAe5YPzKRuUS2lhLmWFeZQW5lJSmHtkWmkwXpgbVVuJhEohIdIDxQW5zBidy4zRJZ1+7u4caGxhT30Tu+sb2VPfyK76JvbUN7K7vpHdB5rYc7CR1W/Usb+hidpDzbR10SyYGzVKC3MpLsilKD9KUV4Og/NzKAqGwfnR4LXDtLy33hfmRinIjVCQGyU/J6LQkR5RSIj0ITOjpCCXkoJcJpUXdTu/u1Pf2ML+hmZqDzVTdyj2uj94rT3UzP6GZuobWzjY2EJ9Ywtv1h0Oxls52NiS8Mil8/qgICdKYV6UgpwIBXnRI+/jw6Qg9633hblR8nIi5OVEyI3GXvOC1/xOpiUaz41GFFIZSCEhEiIzo7ggdqQwrvvZO9XS2sbBplhgtAfJwcZW6htbaGhq4XBzG4ebWznU3MrhYIiNt3GouZXG4H1DUwt7D7Z1Ok9fyo3akeDIiUbIjRjRqJEbiZATNaKRCLlRIxqJn2bkRiPkRIycqJETTI+9D9YRLHdkHcFnR5YJxqNmRCJGNALRSISoxcYjFttOJJgnp308Ykc+i7a/RjosE7zmxC3fvmz8MhEj40JSISGS4XKiEUoLIynrksTdaW51mlrbaGppozl4bWyJvTa1vjXtyPTWNpqD16a4+Zo6TGtpa6Ol1Wlpc5pb22hti22rpa19vH0+f9u8La1tNLc6rcH09vHm1ti8rV2dwwtZxHh78MSFSSQIkojFPo+0B5EZZrBo3ng+edYx/VqvQkJEumRm5OUYeTkRyJBeTtzbw6RDuATh09YGrR4LkzaPzdcWvG91p63trfHWtrfma20jbvytZY8s87Zloa0ttt22d6znrXlb2uKWDZZp35Z7MO7Q5h5KNzMKCREZcMyM3KiRG4XY05Olt3ThtoiIJKSQEBGRhBQSIiKSkEJCREQSUkiIiEhCCgkREUlIISEiIgkpJEREJKGMezKdme0CtvZy8XJgdx+W09dUX++lc22g+o5GOtcG6V1ffG0T3L2ipyvIuJA4GmZW1ZvH9/UX1dd76VwbqL6jkc61QXrX1xe16XSTiIgkpJAQEZGEsi0kbgm7gG6ovt5L59pA9R2NdK4N0ru+o64tq9okRESkZ7LtSEJERHpAISEiIgllTUiY2QIzW2dmG83shpBrGWdmj5vZGjNbbWafC6bfaGbbzWxFMFwcYo1bzOyVoI6qYNpQM3vMzDYEr0NCqm1a3D5aYWZ1Zvb5MPefmd1mZjvNbFXctE73l8X8NPgurjSzk0Oo7Qdm9mqw/T+YWVkwfaKZHYrbh79IZW1d1JfwZ2lmXwv23TozuzCE2n4XV9cWM1sRTA9j3yX6XdJ33z13H/ADsUdTvQYcA+QBLwMzQqxnFHByMF4MrAdmADcCXw57fwV1bQHKO0z7PnBDMH4DcFMa1BkF3gQmhLn/gLOBk4FV3e0v4GLgL4ABpwIvhFDbBUBOMH5TXG0T4+cLcd91+rMM/p+8TOxBqpOC/9fR/qytw+c/Ar4R4r5L9Lukz7572XIkMQ/Y6O6b3L0J+C2wMKxi3H2Hu78YjB8A1gJjwqqnBxYCdwTjdwDvD6+UI84HXnP33t6F3yfc/Slgb4fJifbXQuBOj3keKDOzUf1Zm7s/6u4twdvngbGp2n53Euy7RBYCv3X3RnffDGwk9v+732szMwMuA+5J1fa708Xvkj777mVLSIwBXo97X02a/FI2s4nAbOCFYNL1wWHgbWGdzgk48KiZLTeza4NpI9x9RzD+JjAinNLe5gre/p80XfYfJN5f6fZ9/ASxvy7bTTKzl8zsSTM7K6yi6PxnmU777iygxt03xE0Lbd91+F3SZ9+9bAmJtGRmg4H7gc+7ex3wc+BY4CRgB7FD2bCc6e4nAxcBnzazs+M/9Nixa6jXT5tZHnAJ8PtgUjrtv7dJh/3VGTP7OtAC3B1M2gGMd/fZwBeB35hZSQilpe3PMs4i3v4HSmj7rpPfJUcc7XcvW0JiOzAu7v3YYFpozCyX2A/1bnd/AMDda9y91d3bgP8hhYfR3XH37cHrTuAPQS017YemwevOsOoLXAS86O41kF77L5Bof6XF99HMrgbeC3wk+EVCcBpnTzC+nNg5/6n9XVsXP8t02Xc5wAeB37VPC2vfdfa7hD787mVLSCwDppjZpOCvzyuAxWEVE5zLvBVY6+4/jpsef27wA8Cqjsv2BzMrMrPi9nFijZyriO2zjwWzfQz4vzDqi/O2v+TSZf/FSbS/FgMfDa40ORWojTs10C/MbAHwFeASd2+Im15hZtFg/BhgCrCpP2sLtp3oZ7kYuMLM8s1sUlDf0v6uD3gX8Kq7V7dPCGPfJfpdQl9+9/qzJT7MgVir/npi6f71kGs5k9jh30pgRTBcDNwFvBJMXwyMCqm+Y4hdQfIysLp9fwHDgL8BG4C/AkND3IdFwB6gNG5aaPuPWFjtAJqJnee9JtH+InZlyc3Bd/EVoDKE2jYSOzfd/v37RTDvpcHPfAXwIvC+kPZdwp8l8PVg360DLurv2oLptwP/3GHeMPZdot8lffbdU7ccIiKSULacbhIRkV5QSIiISEIKCRERSUghISIiCSkkREQkIYWEZB0zqw9eJ5rZh/t43f/a4f2zfbl+kf6mkJBsNhHoUUgEd9p25W0h4e6n97AmkbSikJBs9j3grKDv/y+YWdRiz1lYFnQs908AZjbfzJ42s8XAmmDaH4POD1e3d4BoZt8DCoP13R1Maz9qsWDdqyz2nI7L49b9hJndZ7HnO9wd3EWLmX3PYs8JWGlmP+z3vSMCdPdXkchAdgOxZxa8FyD4ZV/r7nPNLB94xsweDeY9GTjeY91TA3zC3feaWSGwzMzud/cbzOx6dz+pk219kFhndScC5cEyTwWfzQZmAm8AzwBnmNlaYt1RTHd3t+ChQCL9TUcSIm+5gFi/NiuIdbc8jFj/OwBL4wIC4LNm9jKxZzGMi5svkTOBezzWaV0N8CQwN27d1R7rzG4FsdNgtcBh4FYz+yDQ8M5ViqSeQkLkLQZ8xt1PCoZJ7t5+JHHwyExm84l18Haau58IvAQUHMV2G+PGW4k9Ma6FWM+n9xHrqfXho1i/SK8pJCSbHSD2yMd2jwCfCrpexsymBr3gdlQK7HP3BjObTuwxkO2a25fv4Gng8qDdo4LYYzET9l4aPB+g1N0fAr5A7DSVSL9Tm4Rks5VAa3Da6HbgJ8RO9bwYNB7vovNHtD4M/HPQbrCO2CmndrcAK83sRXf/SNz0PwCnEetZ14GvuPubQch0phj4PzMrIHaE88Ve/QtFjpJ6gRURkYR0uklERBJSSIiISEIKCRERSUghISIiCSkkREQkIYWEiIgkpJAQEZGE/j8kg5xm1ZdT0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('sc', StandardScaler()),\n",
       "                                       ('mlp', MLPClassifier())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'mlp__hidden_layer_sizes': [(300, 200, 100),\n",
       "                                                     (150, 100, 50),\n",
       "                                                     (75, 50, 25)],\n",
       "                         'mlp__learning_rate': ['constant', 'adaptive'],\n",
       "                         'mlp__max_iter': [100, 200, 300],\n",
       "                         'mlp__solver': ['sgd', 'adam']},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('mlp', MLPClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(300,200,100), (150,100,50), (75,50,25)],\n",
    "    'mlp__max_iter': [100, 200, 300],\n",
    "    'mlp__solver': ['sgd', 'adam'],\n",
    "    'mlp__learning_rate': ['constant','adaptive']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, return_train_score=True, cv=5, n_jobs=4, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'mlp__hidden_layer_sizes': (300, 200, 100), 'mlp__learning_rate': 'constant', 'mlp__max_iter': 100, 'mlp__solver': 'adam'}\n",
      "Best model: Pipeline(steps=[('sc', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(hidden_layer_sizes=(300, 200, 100),\n",
      "                               max_iter=100))])\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best model: {}\".format(grid_search.best_estimator_))\n",
    "print(\"Test score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('iris_model.pkl','wb') as f:\n",
    "    pickle.dump(grid_search.best_estimator_,f)\n",
    "\n",
    "# load\n",
    "with open('iris_model.pkl', 'rb') as f:\n",
    "    model_best = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('sc', StandardScaler()),\n",
       "  ('mlp', MLPClassifier(hidden_layer_sizes=(300, 200, 100), max_iter=100))],\n",
       " 'verbose': False,\n",
       " 'sc': StandardScaler(),\n",
       " 'mlp': MLPClassifier(hidden_layer_sizes=(300, 200, 100), max_iter=100),\n",
       " 'sc__copy': True,\n",
       " 'sc__with_mean': True,\n",
       " 'sc__with_std': True,\n",
       " 'mlp__activation': 'relu',\n",
       " 'mlp__alpha': 0.0001,\n",
       " 'mlp__batch_size': 'auto',\n",
       " 'mlp__beta_1': 0.9,\n",
       " 'mlp__beta_2': 0.999,\n",
       " 'mlp__early_stopping': False,\n",
       " 'mlp__epsilon': 1e-08,\n",
       " 'mlp__hidden_layer_sizes': (300, 200, 100),\n",
       " 'mlp__learning_rate': 'constant',\n",
       " 'mlp__learning_rate_init': 0.001,\n",
       " 'mlp__max_fun': 15000,\n",
       " 'mlp__max_iter': 100,\n",
       " 'mlp__momentum': 0.9,\n",
       " 'mlp__n_iter_no_change': 10,\n",
       " 'mlp__nesterovs_momentum': True,\n",
       " 'mlp__power_t': 0.5,\n",
       " 'mlp__random_state': None,\n",
       " 'mlp__shuffle': True,\n",
       " 'mlp__solver': 'adam',\n",
       " 'mlp__tol': 0.0001,\n",
       " 'mlp__validation_fraction': 0.1,\n",
       " 'mlp__verbose': False,\n",
       " 'mlp__warm_start': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of sklearn's MLP classifier, we can use Keras implemented onto Tensorflow. You will have to choose a Tensorflow kernel on hipergator.\n",
    "\n",
    "\n",
    "Keras: https://keras.io/\n",
    "\n",
    "Tensorflow: https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# Initialize a model.\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add the input layer and specifying its shape.\n",
    "model.add(keras.layers.Input(shape=X_train.shape[1]))\n",
    "\n",
    "# Add the first hidden layer with 100 neurons and the ReLU activation function.\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Add the second hidden layer with 100 neurons and the ReLU activation function.\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "# softmax normalizes the output to a probability distribution\n",
    "model.add(keras.layers.Dense(np.unique(y).shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use the following syntax instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# This line combines the input layer and the first hidden layer.\n",
    "model.add(keras.layers.Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(np.unique(y).shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also use the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu',),\n",
    "    keras.layers.Dense(np.unique(y).shape[0], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the \"architecture\" of our neural network. Note that the input layer does not show up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 10,703\n",
      "Trainable params: 10,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also have a look at the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(2, 100) dtype=float32, numpy=\n",
       " array([[-0.10931191,  0.01835129,  0.12890199, -0.16019647,  0.16109541,\n",
       "         -0.15977046,  0.12739193,  0.07057974,  0.01244342,  0.18932003,\n",
       "         -0.11377046, -0.20269871,  0.09572193,  0.12168288,  0.19243881,\n",
       "         -0.0674421 , -0.17790745,  0.22774225,  0.03085309, -0.12802003,\n",
       "          0.23644903,  0.1059429 , -0.13270022,  0.24171317, -0.06535971,\n",
       "          0.0824655 , -0.22767314, -0.07971008, -0.06973301, -0.10308376,\n",
       "          0.13201639,  0.23760065,  0.00533013,  0.20173737, -0.23473167,\n",
       "         -0.10321838,  0.12525687, -0.15797669,  0.03475195,  0.21055725,\n",
       "         -0.04225342,  0.06461552, -0.2354443 ,  0.16283983, -0.07391682,\n",
       "         -0.00956818,  0.13378045,  0.2372016 , -0.11337712, -0.22723848,\n",
       "         -0.14117748, -0.15303907, -0.16191745,  0.11786127,  0.03434065,\n",
       "         -0.1686477 ,  0.19618165, -0.15822956, -0.06873813,  0.08206004,\n",
       "         -0.21545722,  0.05927148,  0.23922017,  0.18679735, -0.17489123,\n",
       "         -0.1143579 , -0.06211093,  0.01187512, -0.17535454,  0.14599147,\n",
       "          0.19616488, -0.24199386, -0.09219722,  0.05097118, -0.17965215,\n",
       "         -0.23552966,  0.17172503,  0.19637758, -0.03725891,  0.13609096,\n",
       "          0.10322195,  0.13768825, -0.23805788, -0.08814912, -0.18033524,\n",
       "         -0.1611478 ,  0.16577792, -0.10034938, -0.1836005 ,  0.10863131,\n",
       "         -0.12804067, -0.14610827,  0.04726559, -0.13316981,  0.11894619,\n",
       "          0.16400301,  0.03436568,  0.0166252 ,  0.02009124, -0.03504686],\n",
       "        [-0.04708157, -0.15486002, -0.06025943,  0.03716338, -0.04619217,\n",
       "         -0.01922449,  0.10362408,  0.09485617,  0.00380963, -0.04594861,\n",
       "          0.0077042 ,  0.04143715,  0.19131783,  0.06873062,  0.23879892,\n",
       "          0.00435469,  0.05089542, -0.13247222, -0.19573276,  0.09592128,\n",
       "          0.04464126,  0.21171495, -0.1707094 , -0.10630091,  0.14763016,\n",
       "          0.00511242, -0.08748801, -0.06449036, -0.12472997, -0.0834986 ,\n",
       "         -0.15208559, -0.24012502, -0.13510677, -0.06383602, -0.05027051,\n",
       "         -0.19399893,  0.11935467,  0.23011532, -0.149302  ,  0.18839547,\n",
       "         -0.01891872, -0.00589556,  0.22652364,  0.17830697, -0.10749823,\n",
       "         -0.21652749, -0.05546707, -0.21703093, -0.05038691, -0.03996702,\n",
       "          0.0704253 ,  0.09834108, -0.05783702, -0.10186151,  0.18266472,\n",
       "          0.22167611, -0.2211336 ,  0.17734975, -0.08663277,  0.2089063 ,\n",
       "         -0.05302025, -0.07382958,  0.09333324,  0.12567449, -0.12547521,\n",
       "         -0.07148187,  0.0758214 ,  0.07269567, -0.17388995, -0.17490321,\n",
       "          0.00200722,  0.20715737, -0.09645927, -0.04125686,  0.02963382,\n",
       "         -0.12812845,  0.20620689,  0.22294155,  0.08114073,  0.1418246 ,\n",
       "         -0.00689499,  0.12183699, -0.04859798, -0.18239513,  0.08878848,\n",
       "          0.13599572, -0.00770061,  0.00263566, -0.14647609,  0.23106632,\n",
       "         -0.21431696,  0.03379264, -0.05643998, -0.00407626, -0.20465799,\n",
       "         -0.22424927, -0.21992438, -0.21631904, -0.23956358,  0.05654567]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.01886621,  0.01031788,  0.09978649, ..., -0.00928228,\n",
       "         -0.08892234,  0.13273257],\n",
       "        [ 0.06208026,  0.11663735, -0.12947637, ...,  0.02069667,\n",
       "          0.05909276,  0.16641489],\n",
       "        [-0.09177172, -0.04185213, -0.09929659, ...,  0.05978826,\n",
       "          0.071775  ,  0.16799709],\n",
       "        ...,\n",
       "        [-0.04867424, -0.10840853, -0.03665264, ...,  0.16592383,\n",
       "          0.13535938,  0.01803941],\n",
       "        [-0.08143327, -0.14396837, -0.00048216, ...,  0.09100169,\n",
       "          0.02046241, -0.17083015],\n",
       "        [-0.00601862, -0.0049208 , -0.03337178, ..., -0.10469934,\n",
       "          0.07517621,  0.00578031]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(100, 3) dtype=float32, numpy=\n",
       " array([[ 0.18391156,  0.03693685, -0.1933677 ],\n",
       "        [-0.23157643, -0.11963679, -0.101271  ],\n",
       "        [ 0.02393347, -0.17292204, -0.01874483],\n",
       "        [-0.11706045,  0.0832023 ,  0.01221576],\n",
       "        [ 0.08461696, -0.15588489,  0.05288363],\n",
       "        [-0.06616457, -0.17024875, -0.23350085],\n",
       "        [ 0.04422382, -0.155179  , -0.06404833],\n",
       "        [ 0.15891394,  0.08849499, -0.11635692],\n",
       "        [ 0.21164656, -0.04312122, -0.18756379],\n",
       "        [ 0.16336313,  0.21487853,  0.13663712],\n",
       "        [ 0.15729344, -0.14181364, -0.0390465 ],\n",
       "        [-0.11792348, -0.03696866, -0.10307522],\n",
       "        [-0.05668828, -0.23589836,  0.09530798],\n",
       "        [ 0.02649263,  0.18341151,  0.07184193],\n",
       "        [ 0.22126105,  0.18706   ,  0.15487677],\n",
       "        [ 0.22820511, -0.18417102,  0.07492921],\n",
       "        [ 0.16027385,  0.12241712,  0.01841897],\n",
       "        [-0.07925873,  0.23461151,  0.08366564],\n",
       "        [-0.1739396 ,  0.04180163, -0.16960524],\n",
       "        [ 0.0808363 ,  0.09874484, -0.08380456],\n",
       "        [ 0.04579419, -0.14317062, -0.20317882],\n",
       "        [ 0.14707905,  0.1849398 , -0.13252419],\n",
       "        [-0.17170304, -0.02231984, -0.22053444],\n",
       "        [ 0.1733576 ,  0.06735945, -0.18155405],\n",
       "        [ 0.08855805, -0.02170235, -0.22195208],\n",
       "        [-0.07152043,  0.08426347,  0.18340212],\n",
       "        [ 0.22265917, -0.08092099,  0.06269798],\n",
       "        [-0.1591169 , -0.01841563, -0.03478754],\n",
       "        [ 0.11080927, -0.07552886, -0.18167657],\n",
       "        [ 0.1990853 , -0.01469341,  0.00338714],\n",
       "        [-0.11735778, -0.13289869,  0.08116066],\n",
       "        [ 0.08863845,  0.10801172, -0.1600511 ],\n",
       "        [ 0.125265  ,  0.2025832 , -0.13307138],\n",
       "        [ 0.16440427, -0.11480139,  0.01874506],\n",
       "        [ 0.17880711,  0.23999748, -0.03987697],\n",
       "        [ 0.21486324,  0.0406751 , -0.11909099],\n",
       "        [ 0.09569192,  0.11864647, -0.02596028],\n",
       "        [ 0.03240591, -0.07355092, -0.20193595],\n",
       "        [ 0.21312013,  0.13291746, -0.19607824],\n",
       "        [-0.02749014,  0.1661402 ,  0.18336448],\n",
       "        [-0.20921268, -0.22336157,  0.16058633],\n",
       "        [-0.23537908,  0.17916834,  0.1724757 ],\n",
       "        [ 0.05973896,  0.09178305,  0.186005  ],\n",
       "        [-0.16390985,  0.13691938,  0.18677413],\n",
       "        [ 0.00319545, -0.13343666, -0.16848141],\n",
       "        [-0.23534007, -0.01805489, -0.01263221],\n",
       "        [-0.1076207 , -0.02014768,  0.23338702],\n",
       "        [-0.21822263, -0.07434577, -0.17929167],\n",
       "        [ 0.22045958,  0.08094791, -0.20912217],\n",
       "        [-0.15754664, -0.0887647 , -0.08266433],\n",
       "        [ 0.10028648,  0.10851642,  0.02321258],\n",
       "        [-0.08842064, -0.10280995,  0.12573755],\n",
       "        [-0.06088419,  0.11740518, -0.11442587],\n",
       "        [-0.03561564,  0.21563247, -0.02500691],\n",
       "        [ 0.04517749, -0.15080494, -0.1494244 ],\n",
       "        [-0.08957325, -0.07013254,  0.0450106 ],\n",
       "        [-0.01322347, -0.16616988, -0.14342083],\n",
       "        [-0.09122084, -0.19633874, -0.0988967 ],\n",
       "        [-0.11441004,  0.18522161,  0.23365709],\n",
       "        [-0.21122435, -0.00841904, -0.18778965],\n",
       "        [ 0.1619071 ,  0.2241205 , -0.05531482],\n",
       "        [-0.07470265,  0.020567  , -0.22175626],\n",
       "        [ 0.18302742,  0.14124626, -0.0668678 ],\n",
       "        [-0.23987421,  0.02223796,  0.23096377],\n",
       "        [-0.13496906,  0.07366785,  0.07701388],\n",
       "        [-0.21953997,  0.09410033, -0.05532743],\n",
       "        [-0.13303518,  0.17592803, -0.22929367],\n",
       "        [-0.21938397, -0.11641515,  0.15581042],\n",
       "        [-0.1843108 ,  0.07422799, -0.07150467],\n",
       "        [ 0.0871433 , -0.08708028,  0.16406453],\n",
       "        [ 0.23829177,  0.03762689, -0.06436253],\n",
       "        [-0.20707189,  0.05898261, -0.05115858],\n",
       "        [-0.17665365,  0.08763045,  0.09302661],\n",
       "        [-0.08524239, -0.09468743,  0.14260256],\n",
       "        [ 0.22618327, -0.16958107,  0.2240648 ],\n",
       "        [-0.14460796,  0.09728643, -0.06448929],\n",
       "        [-0.12734988, -0.08242632, -0.0612646 ],\n",
       "        [ 0.06320032, -0.01380707,  0.01579371],\n",
       "        [-0.12751491,  0.15076384, -0.04571408],\n",
       "        [-0.04653361, -0.16697642,  0.00780948],\n",
       "        [-0.02999213, -0.08442569, -0.00185923],\n",
       "        [-0.15491885,  0.22182342, -0.10887314],\n",
       "        [-0.02279671,  0.10629806, -0.21924207],\n",
       "        [-0.01287664,  0.1406917 , -0.05090785],\n",
       "        [ 0.18401337,  0.15090495, -0.10730249],\n",
       "        [-0.01577161, -0.18349305, -0.2331655 ],\n",
       "        [ 0.01208472,  0.01004586, -0.22787125],\n",
       "        [ 0.18169624,  0.0629667 , -0.11939568],\n",
       "        [-0.2240076 ,  0.19418553, -0.17756698],\n",
       "        [ 0.02967051,  0.03606269,  0.21949819],\n",
       "        [-0.10386109,  0.0924499 ,  0.2291978 ],\n",
       "        [ 0.06502542, -0.08654225,  0.09577298],\n",
       "        [ 0.01189363,  0.18695083, -0.22250473],\n",
       "        [-0.16079924, -0.05933391,  0.15007788],\n",
       "        [-0.22010644,  0.14665869,  0.23395988],\n",
       "        [ 0.06852511,  0.17212778,  0.11502483],\n",
       "        [ 0.18168515, -0.15300955, -0.11745479],\n",
       "        [ 0.14938688,  0.20981827,  0.1355102 ],\n",
       "        [ 0.06521106, -0.15647948,  0.0108735 ],\n",
       "        [-0.06898449,  0.1862767 ,  0.20979998]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to \"compile\" the model before we fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful links\n",
    "\n",
    "Loss functions: https://keras.io/api/losses/ \n",
    "\n",
    "Optimizers: https://keras.io/api/optimizers/ \n",
    "\n",
    "Metrics: https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are ready to train the neural network. Let's start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa958d8c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa958d8c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0233 - accuracy: 0.5625WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9887e4560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa9887e4560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 1.0057 - accuracy: 0.5370 - val_loss: 0.9843 - val_accuracy: 0.6087\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8910 - accuracy: 0.7609 - val_loss: 0.9236 - val_accuracy: 0.5652\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8168 - accuracy: 0.7241 - val_loss: 0.8723 - val_accuracy: 0.5652\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7302 - accuracy: 0.7436 - val_loss: 0.8299 - val_accuracy: 0.5652\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6533 - accuracy: 0.7553 - val_loss: 0.7942 - val_accuracy: 0.5652\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6215 - accuracy: 0.7375 - val_loss: 0.7629 - val_accuracy: 0.5652\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5477 - accuracy: 0.7726 - val_loss: 0.7358 - val_accuracy: 0.6087\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5126 - accuracy: 0.7687 - val_loss: 0.7101 - val_accuracy: 0.6087\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4917 - accuracy: 0.7665 - val_loss: 0.6828 - val_accuracy: 0.6087\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4712 - accuracy: 0.7800 - val_loss: 0.6558 - val_accuracy: 0.6087\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4528 - accuracy: 0.7661 - val_loss: 0.6309 - val_accuracy: 0.6087\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3796 - accuracy: 0.8168 - val_loss: 0.6065 - val_accuracy: 0.6087\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4081 - accuracy: 0.7968 - val_loss: 0.5819 - val_accuracy: 0.6957\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3661 - accuracy: 0.8449 - val_loss: 0.5565 - val_accuracy: 0.6957\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3551 - accuracy: 0.8293 - val_loss: 0.5285 - val_accuracy: 0.7826\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3167 - accuracy: 0.8701 - val_loss: 0.5032 - val_accuracy: 0.7826\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3342 - accuracy: 0.8388 - val_loss: 0.4785 - val_accuracy: 0.8261\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2897 - accuracy: 0.8640 - val_loss: 0.4538 - val_accuracy: 0.8261\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2694 - accuracy: 0.9121 - val_loss: 0.4299 - val_accuracy: 0.8261\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2621 - accuracy: 0.9199 - val_loss: 0.4094 - val_accuracy: 0.8261\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2452 - accuracy: 0.9238 - val_loss: 0.3833 - val_accuracy: 0.8696\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2594 - accuracy: 0.8943 - val_loss: 0.3581 - val_accuracy: 0.8696\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2124 - accuracy: 0.9468 - val_loss: 0.3442 - val_accuracy: 0.8696\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1837 - accuracy: 0.9563 - val_loss: 0.3303 - val_accuracy: 0.8696\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1964 - accuracy: 0.9250 - val_loss: 0.3148 - val_accuracy: 0.9130\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1667 - accuracy: 0.9658 - val_loss: 0.2951 - val_accuracy: 0.9130\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1802 - accuracy: 0.9524 - val_loss: 0.2775 - val_accuracy: 0.9130\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1612 - accuracy: 0.9485 - val_loss: 0.2666 - val_accuracy: 0.9130\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1475 - accuracy: 0.9563 - val_loss: 0.2584 - val_accuracy: 0.9130\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1404 - accuracy: 0.9407 - val_loss: 0.2616 - val_accuracy: 0.9130\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1267 - accuracy: 0.9463 - val_loss: 0.2674 - val_accuracy: 0.9130\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1175 - accuracy: 0.9697 - val_loss: 0.2595 - val_accuracy: 0.9130\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1330 - accuracy: 0.9385 - val_loss: 0.2506 - val_accuracy: 0.9130\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1260 - accuracy: 0.9385 - val_loss: 0.2378 - val_accuracy: 0.9130\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1111 - accuracy: 0.9580 - val_loss: 0.2240 - val_accuracy: 0.9130\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1013 - accuracy: 0.9636 - val_loss: 0.2233 - val_accuracy: 0.9130\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0985 - accuracy: 0.9558 - val_loss: 0.2261 - val_accuracy: 0.9130\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0825 - accuracy: 0.9792 - val_loss: 0.2231 - val_accuracy: 0.9130\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1014 - accuracy: 0.9597 - val_loss: 0.2251 - val_accuracy: 0.9130\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0744 - accuracy: 0.9714 - val_loss: 0.2223 - val_accuracy: 0.9130\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0832 - accuracy: 0.9558 - val_loss: 0.2328 - val_accuracy: 0.9130\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.2302 - val_accuracy: 0.9130\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9558 - val_loss: 0.2284 - val_accuracy: 0.9130\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0733 - accuracy: 0.9597 - val_loss: 0.2253 - val_accuracy: 0.9130\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0805 - accuracy: 0.9558 - val_loss: 0.2282 - val_accuracy: 0.9130\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0715 - accuracy: 0.9558 - val_loss: 0.2280 - val_accuracy: 0.9130\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0616 - accuracy: 0.9753 - val_loss: 0.2260 - val_accuracy: 0.9130\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0694 - accuracy: 0.9558 - val_loss: 0.2316 - val_accuracy: 0.9130\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0641 - accuracy: 0.9731 - val_loss: 0.2322 - val_accuracy: 0.9130\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0649 - accuracy: 0.9731 - val_loss: 0.2334 - val_accuracy: 0.9130\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0531 - accuracy: 0.9753 - val_loss: 0.2338 - val_accuracy: 0.9130\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0557 - accuracy: 0.9770 - val_loss: 0.2375 - val_accuracy: 0.9130\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0523 - accuracy: 0.9731 - val_loss: 0.2360 - val_accuracy: 0.9130\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9827 - val_loss: 0.2428 - val_accuracy: 0.9130\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9770 - val_loss: 0.2422 - val_accuracy: 0.9130\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 0.9888 - val_loss: 0.2482 - val_accuracy: 0.9130\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0518 - accuracy: 0.9905 - val_loss: 0.2472 - val_accuracy: 0.9130\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0453 - accuracy: 0.9731 - val_loss: 0.2621 - val_accuracy: 0.9130\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0516 - accuracy: 0.9731 - val_loss: 0.2619 - val_accuracy: 0.9130\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9653 - val_loss: 0.2569 - val_accuracy: 0.9130\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0461 - accuracy: 0.9944 - val_loss: 0.2543 - val_accuracy: 0.9130\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9905 - val_loss: 0.2604 - val_accuracy: 0.9130\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9731 - val_loss: 0.2633 - val_accuracy: 0.9130\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 0.9944 - val_loss: 0.2565 - val_accuracy: 0.9130\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.2625 - val_accuracy: 0.9130\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0410 - accuracy: 0.9770 - val_loss: 0.2757 - val_accuracy: 0.9130\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.2741 - val_accuracy: 0.9130\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9130\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9944 - val_loss: 0.2839 - val_accuracy: 0.9130\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0485 - accuracy: 0.9905 - val_loss: 0.2900 - val_accuracy: 0.9130\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.2832 - val_accuracy: 0.9130\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9944 - val_loss: 0.2710 - val_accuracy: 0.9130\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9130\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.2737 - val_accuracy: 0.9130\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9944 - val_loss: 0.2753 - val_accuracy: 0.9130\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9130\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9130\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.3230 - val_accuracy: 0.9130\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0408 - accuracy: 0.9944 - val_loss: 0.3219 - val_accuracy: 0.9130\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0377 - accuracy: 0.9827 - val_loss: 0.2915 - val_accuracy: 0.9130\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9130\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9130\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9130\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9130\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 0.9944 - val_loss: 0.3234 - val_accuracy: 0.9130\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9130\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9130\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9130\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9130\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9130\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9130\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9130\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9130\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9130\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9130\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9130\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9130\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9130\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9130\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9130\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9130\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9130\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9130\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9130\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9130\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9130\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 0.9130\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9130\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9130\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9130\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9130\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9130\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9130\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9130\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9130\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9130\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9130\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9130\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9130\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9130\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9130\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9130\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 0.3953 - val_accuracy: 0.9130\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9130\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9130\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9130\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9130\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9130\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9130\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9130\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9130\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9130\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9130\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9130\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9130\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9130\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9130\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9130\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9130\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9130\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9130\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9130\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9130\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9130\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9130\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9130\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9130\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9130\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9130\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9130\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9130\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9130\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9130\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9130\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9130\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9130\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9130\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9130\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9130\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9130\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9130\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9130\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9130\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9130\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9130\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9130\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9130\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9130\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9130\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9130\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9130\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9130\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9130\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9130\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9130\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9130\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9130\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9130\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9130\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9130\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9130\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9130\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9130\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9130\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9130\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9130\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9130\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9130\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9130\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9130\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9130\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9130\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9130\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9130\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9130\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9130\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9130\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9130\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9130\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9130\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9130\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.9130\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.9130\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9130\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9130\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9130\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9130\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.4526 - val_accuracy: 0.9130\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9130\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.8696\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0294 - accuracy: 0.9731 - val_loss: 0.5652 - val_accuracy: 0.8696\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0273 - accuracy: 0.9827 - val_loss: 0.5268 - val_accuracy: 0.9130\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9130\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9130\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9130\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9130\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9130\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9130\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.9130\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9130\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9130\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.9130\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.9130\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9130\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.9130\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.9130\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.9130\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.9130\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.9130\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.9130\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9130\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.9130\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.9130\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9130\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.9130\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.9130\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.9130\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.9130\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.9130\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.9130\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.9130\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9130\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.9130\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.9130\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9130\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.9130\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.9130\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.9130\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.9130\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9130\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9130\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9130\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.9130\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9130\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.9130\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.9130\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9130\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.9130\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.9130\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9130\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.9130\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.9130\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.9130\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.9130\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.9130\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.5826 - val_accuracy: 0.9130\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.9130\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.9130\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.9130\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.9130\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5852 - val_accuracy: 0.9130\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.9130\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.9130\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9130\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.9130\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.9130\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.9130\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.9130\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.9130\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.9130\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.9130\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9130\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.9130\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9130\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 0.9130\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.9130\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.9130\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 0.9130\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.9130\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9130\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.9130\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.9130\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.9130\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.9130\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.9130\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 0.9130\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.9130\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9130\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.9130\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.9130\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.9130\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.9130\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.9130\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.9130\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.9130\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.9130\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9130\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.9130\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.9130\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.9130\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.9130\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9130\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.9130\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.9130\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.9130\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.9130\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.9130\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.9130\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.9130\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.9130\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.9130\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.9130\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.9130\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.9130\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.9130\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.9130\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.9130\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.9130\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.9130\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.9130\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.9130\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.9130\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.9130\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.9130\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.9130\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.9130\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.9130\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.9130\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.9130\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.9130\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.9130\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.9130\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.9130\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.9130\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.9130\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.9130\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.9130\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.9130\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.9130\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9130\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.9130\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.9130\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.9130\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.9130\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.9130\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.9130\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.9130\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.9130\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.9130\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.9130\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.9130\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.9130\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 0.9130\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.9130\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.9130\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.9130\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.9130\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.9130\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.9130\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.9130\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.9130\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.9130\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.9130\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.9130\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.9130\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.9130\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 0.9130\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.9130\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.9130\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.9130\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.9130\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.9130\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.9130\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.9130\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.9130\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.9130\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.9130\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.9130\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.9130\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.9130\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.9130\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.9130\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.9130\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.9130\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7692 - val_accuracy: 0.9130\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.9130\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7665 - val_accuracy: 0.9130\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.9130\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.9130\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.9130\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.9130\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.9130\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.9130\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.9130\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.9130\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.9130\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.9130\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.9130\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.9130\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.9130\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.7785 - val_accuracy: 0.9130\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.9130\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.9130\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.7691 - val_accuracy: 0.9130\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.9130\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.9130\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.9130\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.9130\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.9130\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7841 - val_accuracy: 0.9130\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.9130\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.9130\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.9130\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.9130\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.9130\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.9130\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.9130\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.9130\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.9130\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7875 - val_accuracy: 0.9130\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7945 - val_accuracy: 0.9130\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.9130\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.9130\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.9130\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.9130\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.9130\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.9130\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.9130\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.9130\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8392 - val_accuracy: 0.9130\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.9130\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.9130\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 0.9130\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.9130\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8224 - val_accuracy: 0.9130\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.9130\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.9130\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.9130\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.9130\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.9130\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.9130\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.9130\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.9130\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.9130\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.9130\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.9130\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 0.9130\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8488 - val_accuracy: 0.9130\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.9130\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.9130\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9130\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.8304 - val_accuracy: 0.9130\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.9130\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.9130\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.9130\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.9130\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.9130\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.9130\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.9130\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.9130\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.9130\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8488 - val_accuracy: 0.9130\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8393 - val_accuracy: 0.9130\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.9130\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.9130\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.9130\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.9130\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9130\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.9130\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8695 - val_accuracy: 0.9130\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.9130\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.9130\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.9130\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.9130\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9130\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.9130\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.9130\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.9130\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.9130\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9130\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8848 - val_accuracy: 0.9130\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.9130\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.9130\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.8546 - val_accuracy: 0.9130\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8531 - val_accuracy: 0.9130\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.9130\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8676 - val_accuracy: 0.9130\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.9130\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.9130\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.9130\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 0.9130\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8415 - val_accuracy: 0.9130\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.9130\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.9130\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.9130\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.9130\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.9130\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8582 - val_accuracy: 0.9130\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.9130\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.9130\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9078 - val_accuracy: 0.9130\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9245 - val_accuracy: 0.9130\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.9130\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.9130\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.9130\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.9130\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.9130\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.9130\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9091 - val_accuracy: 0.9130\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.9130\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.9130\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.9130\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.9130\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.9046 - val_accuracy: 0.9130\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.9130\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9111 - val_accuracy: 0.9130\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.9130\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.9130\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.9130\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.9130\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.9130\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.9130\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.9130\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.9130\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.9130\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.9130\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.9130\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.9130\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.9130\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.9267 - val_accuracy: 0.9130\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.9130\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.9130\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.9130\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.9130\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9130\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.9130\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.9130\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.9130\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.9130\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.9130\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9220 - val_accuracy: 0.9130\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.9130\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.9130\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.9130\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.9130\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9130\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.9130\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.9130\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9130\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.9130\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9130\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.9130\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.9130\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9498 - val_accuracy: 0.9130\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.9130\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.9130\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9130\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.9130\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.9130\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.9130\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.9130\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.9130\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.9130\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.9130\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.9130\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.9130\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.9130\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.9130\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.9130\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.9130\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9839 - val_accuracy: 0.9130\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.9130\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.9130\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.9130\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.9130\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9130\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9130\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.9130\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.9130\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.9130\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.9130\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9831 - val_accuracy: 0.9130\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.9130\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.9130\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.9130\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9130\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.9130\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.9130\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.9130\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.9130\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9130\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.9130\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.9130\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0115 - val_accuracy: 0.9130\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.9130\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.9130\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.9130\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.9130\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.9130\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.9130\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9130\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.9130\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.9130\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.9130\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 0.9130\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.9130\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9130\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.9130\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.9130\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.9130\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.9130\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.9130\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.9130\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.9130\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.9130\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.9130\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0209 - val_accuracy: 0.9130\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0599 - val_accuracy: 0.9130\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.9130\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.9130\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9130\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0211 - val_accuracy: 0.9130\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.9130\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.9130\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0485 - val_accuracy: 0.9130\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0290 - val_accuracy: 0.9130\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.9130\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.9130\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9130\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.9130\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.9130\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.9130\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.9130\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0278 - val_accuracy: 0.9130\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.9130\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.9130\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.9130\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.9130\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0548 - val_accuracy: 0.9130\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.9130\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.9130\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0521 - val_accuracy: 0.9130\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0578 - val_accuracy: 0.9130\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.9130\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.9130\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.9130\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.9130\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.9130\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.9130\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.9130\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.9130\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.9130\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0487 - val_accuracy: 0.9130\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0485 - val_accuracy: 0.9130\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.9130\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.9130\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.9130\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0859 - val_accuracy: 0.9130\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0643 - val_accuracy: 0.9130\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.9130\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.9130\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0730 - val_accuracy: 0.9130\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0867 - val_accuracy: 0.9130\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.9130\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0739 - val_accuracy: 0.9130\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0747 - val_accuracy: 0.9130\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.9130\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.9130\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0580 - val_accuracy: 0.9130\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.9130\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.9130\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.9130\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.9130\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.9130\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9130\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0872 - val_accuracy: 0.9130\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9130\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.9130\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.9130\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.9130\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.9130\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.9130\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.9130\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.9130\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.9130\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.9130\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.9130\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.9130\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.9130\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1007 - val_accuracy: 0.9130\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.9130\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.9130\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.9130\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.9130\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.9130\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.9130\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.9130\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.9130\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1463 - val_accuracy: 0.9130\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1288 - val_accuracy: 0.9130\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.9130\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0710 - val_accuracy: 0.9130\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.9130\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1276 - val_accuracy: 0.9130\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.9130\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9130\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.9130\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1149 - val_accuracy: 0.9130\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.9130\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.9130\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.9130\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.9130\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1538 - val_accuracy: 0.9130\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.9130\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1101 - val_accuracy: 0.9130\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.9130\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0923 - val_accuracy: 0.9130\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1231 - val_accuracy: 0.9130\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.9130\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.9130\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.9130\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1241 - val_accuracy: 0.9130\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1149 - val_accuracy: 0.9130\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9130\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1406 - val_accuracy: 0.9130\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.9130\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.9130\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1342 - val_accuracy: 0.9130\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1278 - val_accuracy: 0.9130\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1195 - val_accuracy: 0.9130\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9130\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.9130\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.9130\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.9130\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.9130\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9130\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.9130\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.9130\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 0.9130\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9130\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.9130\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.9130\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.9130\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.9130\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.9130\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.9130\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.9130\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1409 - val_accuracy: 0.9130\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1569 - val_accuracy: 0.9130\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1745 - val_accuracy: 0.9130\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1650 - val_accuracy: 0.9130\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1638 - val_accuracy: 0.9130\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.9130\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.9130\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.9130\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.9130\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1658 - val_accuracy: 0.9130\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.9130\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1791 - val_accuracy: 0.9130\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.9130\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.9130\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.9130\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.9130\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.9130\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.9130\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.9130\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.9130\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.9130\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1799 - val_accuracy: 0.9130\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2085 - val_accuracy: 0.9130\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2124 - val_accuracy: 0.9130\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1785 - val_accuracy: 0.9130\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.9130\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1648 - val_accuracy: 0.9130\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1960 - val_accuracy: 0.9130\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2116 - val_accuracy: 0.9130\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.9130\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.9130\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.9130\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.9130\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.9130\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.9130\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.9130\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.9130\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.9130\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.9130\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1943 - val_accuracy: 0.9130\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.9130\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.9130\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.9130\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.9130\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1964 - val_accuracy: 0.9130\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.9130\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.9130\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.9130\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2016 - val_accuracy: 0.9130\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.9130\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.9130\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.9130\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.9130\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.9130\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.9130\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2215 - val_accuracy: 0.9130\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.9130\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.9130\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2223 - val_accuracy: 0.9130\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2079 - val_accuracy: 0.9130\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2019 - val_accuracy: 0.9130\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.9130\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.9130\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.9130\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.9130\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.9130\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.9130\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.9130\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.9130\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.9130\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.9130\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.9130\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.9130\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2425 - val_accuracy: 0.9130\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.9130\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2528 - val_accuracy: 0.9130\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.9130\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.9130\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.9130\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.9130\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.9130\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.9130\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.9130\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.9130\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2270 - val_accuracy: 0.9130\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.9130\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.9130\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.9130\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.9130\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.9130\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.9130\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2539 - val_accuracy: 0.9130\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.9130\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.9130\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.9130\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2583 - val_accuracy: 0.9130\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2395 - val_accuracy: 0.9130\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.9130\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.9130\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.9130\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.9130\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.9130\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.9130\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2545 - val_accuracy: 0.9130\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2630 - val_accuracy: 0.9130\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.9130\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2707 - val_accuracy: 0.9130\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.9130\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2521 - val_accuracy: 0.9130\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.9130\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.9130\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 0.9130\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2859 - val_accuracy: 0.9130\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.9130\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2412 - val_accuracy: 0.9130\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.9130\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.9130\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.9130\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.9130\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3055 - val_accuracy: 0.9130\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.9130\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.9130\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.9130\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2760 - val_accuracy: 0.9130\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2922 - val_accuracy: 0.9130\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.9130\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 0.9130\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.9130\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.9130\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.9130\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.9130\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2981 - val_accuracy: 0.9130\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.9130\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.9130\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.9130\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2787 - val_accuracy: 0.9130\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.9130\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.9130\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3218 - val_accuracy: 0.9130\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.9130\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2866 - val_accuracy: 0.9130\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2945 - val_accuracy: 0.9130\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3040 - val_accuracy: 0.9130\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3018 - val_accuracy: 0.9130\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.9130\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.9130\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.9130\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3012 - val_accuracy: 0.9130\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.9130\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.9130\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3246 - val_accuracy: 0.9130\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.9130\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.9130\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.9130\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.9130\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3128 - val_accuracy: 0.9130\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.9130\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2989 - val_accuracy: 0.9130\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3079 - val_accuracy: 0.9130\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.9130\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3458 - val_accuracy: 0.9130\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.9130\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.9130\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.9130\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 0.9130\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3240 - val_accuracy: 0.9130\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3242 - val_accuracy: 0.9130\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.9130\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.9130\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.9130\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3140 - val_accuracy: 0.9130\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.9130\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.9130\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.9130\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.9130\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9130\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.9130\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.9130\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.9130\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.9130\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.9130\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.9130\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.9130\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.9130\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.9130\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.9130\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3588 - val_accuracy: 0.9130\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3645 - val_accuracy: 0.9130\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.9130\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.9130\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.9130\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3165 - val_accuracy: 0.9130\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3444 - val_accuracy: 0.9130\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3680 - val_accuracy: 0.9130\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.9130\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.9130\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3522 - val_accuracy: 0.9130\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.9130\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.9130\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3600 - val_accuracy: 0.9130\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.9130\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3595 - val_accuracy: 0.9130\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.9130\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.9130\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3809 - val_accuracy: 0.9130\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.9130\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3663 - val_accuracy: 0.9130\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3602 - val_accuracy: 0.9130\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.9130\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3560 - val_accuracy: 0.9130\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.9130\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4129 - val_accuracy: 0.9130\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.9130\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 0.9130\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3523 - val_accuracy: 0.9130\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.9130\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.9130\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.9130\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4096 - val_accuracy: 0.9130\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.9130\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.9130\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.9130\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.9130\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.9130\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3740 - val_accuracy: 0.9130\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.9130\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3887 - val_accuracy: 0.9130\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.9130\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.9130\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3790 - val_accuracy: 0.9130\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3766 - val_accuracy: 0.9130\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.9130\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3867 - val_accuracy: 0.9130\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.9130\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.9130\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4192 - val_accuracy: 0.9130\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.9130\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3897 - val_accuracy: 0.9130\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.9130\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.9130\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4065 - val_accuracy: 0.9130\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4144 - val_accuracy: 0.9130\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4076 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "# history will record the loss, accuracy, etc. \n",
    "# validation_split will split the training dataset into training + validation datasets. \n",
    "history = model.fit(X_train_scaled, y_train, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that in each epoch, there are 3 mini batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8000000000000003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[0]*0.8)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape[0]/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evlauate the model using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3425881266593933\n",
      "Test accuracy: 0.9736841917037964\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and validation loss evolved over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa999b5fb50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how accuracy and validation accuracy evolved over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa979388110>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The default monitor is \"val_loss\"\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu',),\n",
    "    keras.layers.Dense(np.unique(y).shape[0], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9b8ddd560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa9b8ddd560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0343 - accuracy: 0.7500WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa96c5f5a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa96c5f5a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3/3 [==============================] - 1s 107ms/step - loss: 1.0370 - accuracy: 0.5753 - val_loss: 1.0935 - val_accuracy: 0.2609\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.9669 - accuracy: 0.3880 - val_loss: 1.0558 - val_accuracy: 0.2609\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9222 - accuracy: 0.4193 - val_loss: 1.0360 - val_accuracy: 0.2609\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9095 - accuracy: 0.4154 - val_loss: 1.0042 - val_accuracy: 0.2609\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9110 - accuracy: 0.3958 - val_loss: 0.9791 - val_accuracy: 0.2609\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8905 - accuracy: 0.4037 - val_loss: 0.9633 - val_accuracy: 0.2609\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9180 - accuracy: 0.3490 - val_loss: 0.9503 - val_accuracy: 0.2609\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8753 - accuracy: 0.4166 - val_loss: 0.9633 - val_accuracy: 0.3913\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8500 - accuracy: 0.6137 - val_loss: 0.9599 - val_accuracy: 0.4783\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8503 - accuracy: 0.6518 - val_loss: 0.9344 - val_accuracy: 0.4783\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8304 - accuracy: 0.6864 - val_loss: 0.9170 - val_accuracy: 0.4783\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8314 - accuracy: 0.6821 - val_loss: 0.8926 - val_accuracy: 0.5217\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8148 - accuracy: 0.7150 - val_loss: 0.8781 - val_accuracy: 0.5217\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7817 - accuracy: 0.7189 - val_loss: 0.8757 - val_accuracy: 0.5217\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7522 - accuracy: 0.7033 - val_loss: 0.8652 - val_accuracy: 0.5217\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7421 - accuracy: 0.7167 - val_loss: 0.8422 - val_accuracy: 0.5217\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7066 - accuracy: 0.7284 - val_loss: 0.8189 - val_accuracy: 0.5217\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7184 - accuracy: 0.7245 - val_loss: 0.7872 - val_accuracy: 0.5217\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7098 - accuracy: 0.7223 - val_loss: 0.7613 - val_accuracy: 0.5217\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6560 - accuracy: 0.7653 - val_loss: 0.7716 - val_accuracy: 0.5217\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6476 - accuracy: 0.7380 - val_loss: 0.7635 - val_accuracy: 0.5217\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6297 - accuracy: 0.7223 - val_loss: 0.7359 - val_accuracy: 0.5217\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.6090 - accuracy: 0.7223 - val_loss: 0.6993 - val_accuracy: 0.5652\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5817 - accuracy: 0.7380 - val_loss: 0.6753 - val_accuracy: 0.6087\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5510 - accuracy: 0.7536 - val_loss: 0.6588 - val_accuracy: 0.6522\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5298 - accuracy: 0.7570 - val_loss: 0.6414 - val_accuracy: 0.6522\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5170 - accuracy: 0.7648 - val_loss: 0.6258 - val_accuracy: 0.6522\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5054 - accuracy: 0.7722 - val_loss: 0.6082 - val_accuracy: 0.6522\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5035 - accuracy: 0.7565 - val_loss: 0.5811 - val_accuracy: 0.6522\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4849 - accuracy: 0.7678 - val_loss: 0.5655 - val_accuracy: 0.6522\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4450 - accuracy: 0.8208 - val_loss: 0.5778 - val_accuracy: 0.6522\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4562 - accuracy: 0.7622 - val_loss: 0.5445 - val_accuracy: 0.6957\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4339 - accuracy: 0.7873 - val_loss: 0.5139 - val_accuracy: 0.7826\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4077 - accuracy: 0.8623 - val_loss: 0.5071 - val_accuracy: 0.7826\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.90 - 0s 21ms/step - loss: 0.3984 - accuracy: 0.8437 - val_loss: 0.5081 - val_accuracy: 0.7391\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3678 - accuracy: 0.8359 - val_loss: 0.4912 - val_accuracy: 0.7826\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3930 - accuracy: 0.8484 - val_loss: 0.4575 - val_accuracy: 0.8696\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3540 - accuracy: 0.8948 - val_loss: 0.4561 - val_accuracy: 0.8696\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3645 - accuracy: 0.8891 - val_loss: 0.4384 - val_accuracy: 0.8696\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3689 - accuracy: 0.8987 - val_loss: 0.4467 - val_accuracy: 0.8696\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3388 - accuracy: 0.8579 - val_loss: 0.4340 - val_accuracy: 0.8696\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3278 - accuracy: 0.9004 - val_loss: 0.4148 - val_accuracy: 0.8696\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3177 - accuracy: 0.9199 - val_loss: 0.3920 - val_accuracy: 0.9130\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3111 - accuracy: 0.9121 - val_loss: 0.3900 - val_accuracy: 0.9130\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3111 - accuracy: 0.9065 - val_loss: 0.3941 - val_accuracy: 0.8696\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3070 - accuracy: 0.9082 - val_loss: 0.3832 - val_accuracy: 0.8696\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2878 - accuracy: 0.8640 - val_loss: 0.3841 - val_accuracy: 0.8696\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3227 - accuracy: 0.8752 - val_loss: 0.3381 - val_accuracy: 0.9130\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2630 - accuracy: 0.9294 - val_loss: 0.3488 - val_accuracy: 0.9130\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2723 - accuracy: 0.9255 - val_loss: 0.3490 - val_accuracy: 0.9130\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2663 - accuracy: 0.9060 - val_loss: 0.3450 - val_accuracy: 0.9130\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2575 - accuracy: 0.9255 - val_loss: 0.3189 - val_accuracy: 0.9130\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2425 - accuracy: 0.9177 - val_loss: 0.3309 - val_accuracy: 0.9130\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2494 - accuracy: 0.9099 - val_loss: 0.3169 - val_accuracy: 0.9130\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2562 - accuracy: 0.9099 - val_loss: 0.3308 - val_accuracy: 0.9130\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2295 - accuracy: 0.9216 - val_loss: 0.3055 - val_accuracy: 0.9130\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2159 - accuracy: 0.9216 - val_loss: 0.2983 - val_accuracy: 0.9130\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2355 - accuracy: 0.9138 - val_loss: 0.2950 - val_accuracy: 0.9130\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2115 - accuracy: 0.9429 - val_loss: 0.2758 - val_accuracy: 0.9130\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1945 - accuracy: 0.9624 - val_loss: 0.3062 - val_accuracy: 0.9130\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2086 - accuracy: 0.9450 - val_loss: 0.3029 - val_accuracy: 0.9130\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2144 - accuracy: 0.9255 - val_loss: 0.2981 - val_accuracy: 0.9130\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2108 - accuracy: 0.9177 - val_loss: 0.2728 - val_accuracy: 0.9130\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1750 - accuracy: 0.9507 - val_loss: 0.2637 - val_accuracy: 0.9130\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2037 - accuracy: 0.9311 - val_loss: 0.2661 - val_accuracy: 0.9130\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2103 - accuracy: 0.9177 - val_loss: 0.2818 - val_accuracy: 0.9130\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1854 - accuracy: 0.9294 - val_loss: 0.2657 - val_accuracy: 0.9130\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1912 - accuracy: 0.9272 - val_loss: 0.2456 - val_accuracy: 0.9130\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1980 - accuracy: 0.9272 - val_loss: 0.2478 - val_accuracy: 0.9130\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1800 - accuracy: 0.9311 - val_loss: 0.2461 - val_accuracy: 0.9130\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1872 - accuracy: 0.9272 - val_loss: 0.2612 - val_accuracy: 0.9130\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1802 - accuracy: 0.9216 - val_loss: 0.2670 - val_accuracy: 0.9130\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1695 - accuracy: 0.9333 - val_loss: 0.2519 - val_accuracy: 0.9130\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1768 - accuracy: 0.9233 - val_loss: 0.2457 - val_accuracy: 0.9130\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1828 - accuracy: 0.9272 - val_loss: 0.2540 - val_accuracy: 0.9130\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1704 - accuracy: 0.9311 - val_loss: 0.2411 - val_accuracy: 0.9130\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1643 - accuracy: 0.9272 - val_loss: 0.2494 - val_accuracy: 0.9130\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1823 - accuracy: 0.9116 - val_loss: 0.2403 - val_accuracy: 0.9130\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1484 - accuracy: 0.9468 - val_loss: 0.2417 - val_accuracy: 0.9130\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1413 - accuracy: 0.9585 - val_loss: 0.2503 - val_accuracy: 0.9130\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1555 - accuracy: 0.9311 - val_loss: 0.2445 - val_accuracy: 0.9130\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1564 - accuracy: 0.9272 - val_loss: 0.2272 - val_accuracy: 0.9130\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1703 - accuracy: 0.9289 - val_loss: 0.2351 - val_accuracy: 0.9130\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1570 - accuracy: 0.9350 - val_loss: 0.2499 - val_accuracy: 0.9130\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1620 - accuracy: 0.9272 - val_loss: 0.2457 - val_accuracy: 0.9130\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1505 - accuracy: 0.9311 - val_loss: 0.2247 - val_accuracy: 0.9130\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1620 - accuracy: 0.9368 - val_loss: 0.2193 - val_accuracy: 0.9130\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1540 - accuracy: 0.9328 - val_loss: 0.2513 - val_accuracy: 0.9130\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1399 - accuracy: 0.9411 - val_loss: 0.2604 - val_accuracy: 0.9130\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1482 - accuracy: 0.9177 - val_loss: 0.2342 - val_accuracy: 0.9130\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1665 - accuracy: 0.9211 - val_loss: 0.2101 - val_accuracy: 0.9130\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1483 - accuracy: 0.9368 - val_loss: 0.2158 - val_accuracy: 0.9130\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1386 - accuracy: 0.9524 - val_loss: 0.2448 - val_accuracy: 0.9130\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1371 - accuracy: 0.9429 - val_loss: 0.2713 - val_accuracy: 0.9130\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1059 - accuracy: 0.9529 - val_loss: 0.2356 - val_accuracy: 0.9130\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1241 - accuracy: 0.9446 - val_loss: 0.1929 - val_accuracy: 0.9130\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1512 - accuracy: 0.9328 - val_loss: 0.2187 - val_accuracy: 0.9130\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1366 - accuracy: 0.9446 - val_loss: 0.2400 - val_accuracy: 0.9130\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1189 - accuracy: 0.9429 - val_loss: 0.2262 - val_accuracy: 0.9130\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1162 - accuracy: 0.9524 - val_loss: 0.2049 - val_accuracy: 0.9130\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1391 - accuracy: 0.9328 - val_loss: 0.2218 - val_accuracy: 0.9130\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1290 - accuracy: 0.9389 - val_loss: 0.2676 - val_accuracy: 0.9130\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1066 - accuracy: 0.9411 - val_loss: 0.2365 - val_accuracy: 0.9130\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1192 - accuracy: 0.9580 - val_loss: 0.1784 - val_accuracy: 0.9130\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1076 - accuracy: 0.9831 - val_loss: 0.1931 - val_accuracy: 0.9130\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1263 - accuracy: 0.9368 - val_loss: 0.2799 - val_accuracy: 0.9130\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1249 - accuracy: 0.9372 - val_loss: 0.3184 - val_accuracy: 0.8696\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1458 - accuracy: 0.9194 - val_loss: 0.2052 - val_accuracy: 0.9130\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1396 - accuracy: 0.9541 - val_loss: 0.1588 - val_accuracy: 0.9130\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1496 - accuracy: 0.9446 - val_loss: 0.2233 - val_accuracy: 0.9130\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1091 - accuracy: 0.9333 - val_loss: 0.2770 - val_accuracy: 0.9130\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1266 - accuracy: 0.9272 - val_loss: 0.2214 - val_accuracy: 0.9130\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1249 - accuracy: 0.9368 - val_loss: 0.1908 - val_accuracy: 0.9130\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1394 - accuracy: 0.9211 - val_loss: 0.1999 - val_accuracy: 0.9130\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1333 - accuracy: 0.9289 - val_loss: 0.2406 - val_accuracy: 0.9130\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1325 - accuracy: 0.9289 - val_loss: 0.2488 - val_accuracy: 0.9130\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1172 - accuracy: 0.9289 - val_loss: 0.2120 - val_accuracy: 0.9130\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1417 - accuracy: 0.9211 - val_loss: 0.1826 - val_accuracy: 0.9130\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0969 - accuracy: 0.9658 - val_loss: 0.1960 - val_accuracy: 0.9130\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1287 - accuracy: 0.9289 - val_loss: 0.2441 - val_accuracy: 0.9130\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1058 - accuracy: 0.9563 - val_loss: 0.2483 - val_accuracy: 0.9130\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1247 - accuracy: 0.9502 - val_loss: 0.2359 - val_accuracy: 0.9130\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1104 - accuracy: 0.9485 - val_loss: 0.1989 - val_accuracy: 0.9130\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1247 - accuracy: 0.9289 - val_loss: 0.1865 - val_accuracy: 0.9130\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1111 - accuracy: 0.9485 - val_loss: 0.2192 - val_accuracy: 0.9130\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0975 - accuracy: 0.9602 - val_loss: 0.2247 - val_accuracy: 0.9130\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0815 - accuracy: 0.9641 - val_loss: 0.2221 - val_accuracy: 0.9130\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0942 - accuracy: 0.9563 - val_loss: 0.2314 - val_accuracy: 0.9130\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1160 - accuracy: 0.9446 - val_loss: 0.2273 - val_accuracy: 0.9130\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1184 - accuracy: 0.9368 - val_loss: 0.2211 - val_accuracy: 0.9130\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1310 - accuracy: 0.9250 - val_loss: 0.2238 - val_accuracy: 0.9130\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0989 - accuracy: 0.9485 - val_loss: 0.2010 - val_accuracy: 0.9130\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0979 - accuracy: 0.9485 - val_loss: 0.2206 - val_accuracy: 0.9130\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1016 - accuracy: 0.9485 - val_loss: 0.2160 - val_accuracy: 0.9130\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1021 - accuracy: 0.9407 - val_loss: 0.2124 - val_accuracy: 0.9130\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1035 - accuracy: 0.9407 - val_loss: 0.2088 - val_accuracy: 0.9130\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0791 - accuracy: 0.9680 - val_loss: 0.2136 - val_accuracy: 0.9130\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0929 - accuracy: 0.9658 - val_loss: 0.2552 - val_accuracy: 0.9130\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0981 - accuracy: 0.9619 - val_loss: 0.2314 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa999c77cd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa96c661d50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABDAElEQVR4nO3deXxU9bn48c8zk4QQwhIggEBIUFGQTQhLXHCtrbaKS4uotC51ue11aWt7e7X1VmuXn7et1rbX24pWxVvXulS0LpWKitYIRBHZQUggICGEsCckM/P8/jhnhslkOwmZzCTzvF+vMHPOfOfMM4dkvnO+y/MVVcUYY0zq8iU6AGOMMYllFYExxqQ4qwiMMSbFWUVgjDEpzioCY4xJcVYRGGNMiotbRSAij4jIDhFZ0czjIiK/F5ENIrJcRCbHKxZjjDHNi+cVwWPAuS08fh4wyv25AfhjHGMxxhjTjLhVBKr6LrCrhSIXAo+roxjoJyJHxSseY4wxTUtL4GsPA7ZEbZe7+z5v6UkDBw7UgoKCOIZljDHdT0lJyU5VzW3qsURWBJ6JyA04zUeMGDGCpUuXJjgiY4zpWkSkrLnHEjlqaCuQF7U93N3XiKrOVdUpqjolN7fJCs0YY0w7JbIimA9c6Y4eKgL2qGqLzULGGGM6XtyahkTkKeAMYKCIlAN3AukAqvon4FXgy8AG4CBwTbxiMcYY07y4VQSqenkrjytwY7xe3xhjjDc2s9gYY1KcVQTGGJPirCIwxiRMSVk1DyzcQElZdaJDSWldYh6BMab7WVq6i8sfKiYYUjLSfDxxXRGF+TmJDisl2RWBMSYh/vftz6gPKiGF+kCI4o1ViQ4pZdkVgTGmU5WUVfPK8m28s25HZF96mo+iowc0WbZ4YxVFRw/o8KuF5o4dz9dsq+hYgLjFZRWBMabTlJRVM+fhYmrrQwCcP34Ir3y6ndvPG9Powy1cti4Q6vCmo6Wlu7jioQ8JhBoeu6SsmiseKqY+2PGv2Vbh93+oPoTPB4IQ0vg0o1nTkDGm0xRvrOKQWwn4BEYN7k2vDD9rtu9ttmxI4VB9xzYd/c9bG6gLhho1S72/oZJDAWd/XYKbq8LvX4FgCAKh+DWjWUVgjOk0RUcPwOcTADLSfJw6Kpcvjh3Cq59upy4QalRWnKIokJud0SExrP58L+9t2BnZ9vsON0t9Vnkgsl8VJo/o1yGv2R69evhRQIB0v5DuF/zSfDPakbCmIWO6qMWbqli0fidnHD+o2WaC9zbs5PUV2+md6QeEL4wZ3KjsP1Zu5931O+md6WdfbZDemX58Ipw1unHZBasqeHtdZYOygnB21HFfX/E5722ook+mn54ZaZx8zMDIY4X5OeT370kgBL+dfSKF+Tnsra3nxY+3ctvzy5lTlB8pe0xuL0Rg/NA+bNtdy/0L1rNtTy0zRuU2bNMv3cX8T7YxZmgfAFZs3dsgvujb7B5+nispp1ePNO65ZDy3v/gpqsoLH5XzzJLNvLRsG1PzcxgxMIvnS7Zyz2truHz6iFaPG74dN6z1GLyUzc7w88SHmxnQK4NvnJTPjFFOss149RGIk+mh65gyZYpaGmqT6paW7uLSBz8gpNAjzceT1zduM160vpIr/7yY6L/wzPSG7cv/2rCTKx7+sMnXiD3uB5/t5PKHWi77aflu7np5VYPHol9z/6EAE+56g5vOGsWt5xwHOBXapQ8WNyr71OLN3P7Cp7xy86ksLd3FXS+vQoAe6Q3b9C998AOCobZ9jmX4haduOIl1Ffu4/YVPG8ab5uMnF4zlv15a0ebjdrSMNB9PNfF/2x4iUqKqU5p6zJqGjOmCHli4gfBn1KFAiA8+29mozH+/tobYj7HYdu8nF29u9jUOBUL8K+q4zyzZ0mLZt9ZUcO8/1jV+LKp9f9nm3YQUpkR9sC0pPTyZLLr9+6VlWzk6txdjh/bhQF0QcJqIoss8ubgs8mEtzUbXWDCkFG+sYteBOnwxT6wPhnhtxeeEvyS35bgdXTYY7Jx+CmsaMimhpKyad9ftoE/PdPbXBjg1pnmhrWVLSnfxzrpK+mals+dgfeR2SkF//D5h2ZbdTQ5LfHddZWTf0tJdjZ7f1PFiy9aHQryzttJpP1fnw/GtNTuYMLxfpGzFvkOs2LYXvwiqSnTre3T78vY9tYDzjTCE8+GkUbf/WFkRadrZsfdQi2X//N4m6uqd0TaBQCjymgqs2raXkrJqlpTuwicwKartvejoAWT4fdQFQ/h8QtHRA3hzZQXFG3dx6ZThiDj70nxCIKSk+Z028oVrd/D3Tz5HcDqe/T4Bkchrx8YXvvXFtLNnpPmoq3eeE37svHFHsaR0F/WBUJuOm9aBZWPjjCdrGjLdXlPNB81dcpeUVTP7wQ8IRJf1+3jqhqIGH+DhZpnmNNWEEXvcI5XuF848bhBvrqmguT/jDL8wa0oeY4f25dmlm1m1bS8f/+SL9OqRxu6DdUz9xQLOGzeE44f0IScrg+qDdeRkZbBi2x6eXryZkDrn6s9XTeG6eUs5a/Qgxg3r22zZNJ9w94XjIo8tLd3FCx87601lpvsYNSibkMLfb5nRIM6lpbu45tElHDekNz/68pjIuYpunlq4poJvzlvKxScOY870Ecxy/w/S/MLsKXlcMnk44LSjR8fX1G10JR0eqx/7WFNj+L0ctyPLdmR/QEtNQ3ZFYLq9pxZvbtTWWxcIsSjq23nYs0s3N/qwrguGeGfdjkjZP779WYuVADjf6MLNMIX5Obz48dYOrQQAQiGlJhCMfINsSjCkDO3Xkyumj2DU4Gxm/ekD3lxVwUWThvHaiu3UB5XrZxzD+OF9GzzvgYUbIvfrAiEe/6CMQ4EQ180YSWF+/2bLqirVB+u48cxjAag+WBeJ71B9iDXb9zFnen6jOKcU9OeKohH8edEmnvywLHKuAsHD5/DM0YM5bVQuH27axcG6YOT/QN33GN0h3RaF+TlNPid2f1uOG6+y8WIVgUkqTX07g/Z/w8pI8/HKJ9sQnG/p0Zfg723YSXqaL1I2M83Hy8ucRfJimz/eXVdJjzQ/9YEQC9fuQAREG5aJXO4DdW7qhM27DvDY+5t46eNyAPxtbMJorvnASxNGbNNC4YgcBvbK4Pf/XE9e/yyeKC4jJyudukCw0f9D0dEDnCYTd0z9P1dV0CczrckaJ1y2PhBq1JRRdPQAeqT7IuPh64NK/15NDwOdOXEoD76zkRc+2ho5V7HHu/DEodz67Cds210TaRLqrOaT7syahkzSiEfzSVi4+WDs0L5UH6zjw41VvLu+cQdrU2VLynbx1prKBmXS/cKlUWViK6MH3lrPW2sbPifNJ8ye2vYmjObKemnCiG0CiW0ii23CihY+bvFGZ5iql7JNNWWUlFXzzJLNPLvUqQybG+VUUrqLr/3pAzTmXEWXe2/DTr7ujnIK/x/EljFNs6YhkxhbFkPpIug5AGqqoGAG5E1rtmzd23/ja9TS37+fXZpNf9lPcWgMAEW+1ZF9zd22VHY32Zy/N5OT8o6DtCpy+xewXzZ7KvvXfgXsjikbWwb/AOfW57R9X+/7G4N8tU0et9B3EQCFaYsOP6+5W/d4TZatHACbqyjsOYDC5sq6Zeg5gLqV67hUasnxNzxXu0PZ1L29CMYe5/w/uf9f4ePm9s/ngGzxVBbfDNhCg//3wp4DqDuwDr+/lhz2s1vdY5zlnIdw2bqV65jsy6UkdBwnspbz975HYeVxTvwFznvzv/83LnPPa+R8xpRp8DvX3G1XLtvS31E72RWB6XAlZdVs+nghF39yAz6td/cK6u+B7+qXIW9aw2+QvvXw2FfQYF1kFEy4CSSEuM062mwTiteyyOEhe4qPkOoRlY0uc5gPBFRDjd7L4ef43J2hRs9urOPKqvtPU+eq6fcSfl7D999S2eZiiH7t5s6DItRqOj8LfIOfpD1OD6mPep2mz2vDWBJzXju1LIC/B1w1v82VQcKuCETkXOB3gB94WFXviXk8H3gEyAV2AV9X1fJ4xmTia0npLmY/+AHf8r2OL60eEWeqvogSDNTx+bJ/sGpvPv/2F6cyz0jz8c9pJQwLHu5U9Il7i/NBBVFt4y3ctlY2+sNLCOGTIyvb9Ieh80ElgEpzxw0137vbzPE6omx0TLHnqvkP9sbvv6WyzcUQez6aOg+CkukL8m+DVtKjOhDzOk2f16bKeNOFywbrnCuDDrwqiNuEMhHxAw8A5wEnAJeLyAkxxX4DPK6qE4C7gf8Xr3hM53hu6RZCCqtC+YhAMOoXPYCfD4Jj+PnfVxFSIgm0ltYVAE7Ha/hrnnPjQ/wZiL8H4HP/6KXpW49lccvSQWVpoiwtHTemDE0dp5njdUTZls5VS8dtS9nmYmj9PID4M8g/5XIknGSoibIt/T8l6rx2WlnxO/fDTUUdJJ5XBNOADaq6EUBEngYuBKLnn58A3OreXwj8LY7xmA4Q2ykYu71zfx0AAXF+tZ4LnkGl9uam9Je5P3AJb20aSNmu/ZHjpaf5OD5vEHwKzwdmMHDMDM4ckZa87bMdUbarxNmZZbd+BGtegcuegGPPhn/eBf1GQOE37bx2Qh9BPCuCYTjdRmHlwPSYMp8Al+A0H10M9BaRAapaFce4TDuVlFVz2dwPIksL/uT8sfz05ZXUBUL0SPfx2DVTWVK6i9OPG8j16bXwGeyfcQe52b0JvfkKPQiwrmI/PoHxw/qyYcd+Hv/mNLLW/AWAewOXsnt1Lk+c2kRulbb84neVsl0lzs4ou+4fTkWQ3hP2V0JNNZz2HzDl6rYfN1neU6LLtkGicw39ADhdRD4GTge2AsHYQiJyg4gsFZGllZWVsQ+bTvLOuh2RpQXrAiH+vnwbhwKhyGShZxZvYW9tgKtPGcmp2dshewjXfmkqs08ZzZ6eIxjtc/LaCJDbJ5MDdUFye2eyp/QjqjWb7fSnvpNyq5gkM2Scc1uxEipWOPcHj0tcPCkmnhXBViAvanu4uy9CVbep6iWqOgn4sbtvd+yBVHWuqk5R1Sm5ublxDNm0JHr8uTNZ6mBkW4EPN+2iZ7qfXhl+54958NjDTx48lhN8myOThL48bggAS8t2kXtgA2tCI/CJ2OSgVNX7KOiZA9s/dSoDaPj7Y+IqnhXBEmCUiIwUkQzgMmB+dAERGSgi4RhuxxlBZJLU8vI9DOnTg5OOdlIMbKmuwScwq3A4fTLT2Lanlpr6INc88gGhHWsa/CHnjJxEvlTwn2fn8cR1RVx04jB6Z6axdFMV/favZ6M/n++dc1xClwY0CSTiXAGErwiyh0CvgYmOKmXErSJQ1QBwE/AGsBp4VlVXisjdIjLTLXYGsFZE1gGDgV/EKx5zZHbsq+X9DTuZNSWPU0cd/gMVoGBgL85zv+ED5AW34gvVwZDxhw/gXubfcPwhCvNz8PmEwvwcPlu3gkytJXvEJG4+a5RVAqls8DjYscq5KhhizUKdKa7zCFT1VeDVmH0/ibr/HPBcPGMwHeNPbqK1Y3OzGd4/i8z0DQ1yyxQdPYCXPtlGfSDE2DR3jEBM0xAAFZ9C3lQAphb0Z/n6dZABmcMndPI7Mkln8FioP+hcERx7dqKjSSmWYsK0qqSsmkf/VQrAf76wnCeuK+KJ64oa5ZYJ77tk1yJYmQ4DRh0+SL8R0KPP4fZfoE9mGmN8mwmq8MNFdQw8vtquCFJZgy8OdkXQmawiMK1auGYHk1hHkf9wrpmTxh7n5JYJ57IpmEGhz81z8/nbkNUfPl92eLibiFMZrHsDJswG4Og1LzJJStit2YwKbqR441irCFLZoDFE5i93sdQ3XV2rFYGI3As8oqorWytruqcJrOXmjJ+TRsDpVNrk/kSIM/tRBEKBw7vnzTycE2XLYtixGjQIj5wLIpwcCkR6qf4v/ZeUZY8Hju2st2WSzfZPD99/+RboPzJu4+ZNQ146i1cDc0XkQxH5loj0bfUZpksq3riT+xeso6SsusH+EVXv00MC+MX5rG+ca0adD/joSgAO50QB5zacXMstK7jHE8j0BRld+0kc3pXpMsK/KwDB+obbJq5arQhU9WFVPQW4EigAlovIkyJyZryDM52npKyaOQ8t5v4F65nzcHGDymAjQ4Ho/FjN5ULJIPIrFd4XnhpfMAPSMg/nSokpK3HIn2K6mNjfEft96DSe+gjcBHKj3Z+dOKkhbhWRf1PVy+IYn+kkxRurCLrtsvVRSywCbKrtDYBMvhKGFnrPmxKdEyVvmtNMFM6V0lJZk5pif0fs96HTeOkj+C1wPvAW8EtVXew+9N8isjaewZnOUzTy8Dq0af6Gs3sP7d7m3DnpJsg9vuUDtfTHmzet4eP2h25ixf6OmE7h5YpgOXCHqh5o4jH7H+sm8gZkRe5/+4xjGoze0X07nDu9LL2HMd2Rl87i3URVGCLST0QuAlDVPfEJy3S2sqrDeYPqAodXTNpbW09W/S6CkubkgjHGdDteKoI7oz/w3aRwd8YtIpMQpTudC77sHmms3b4vsn9z1UEGsof6zAHO8B5jTLfjpSJoqoxNROtmyqoO4vcJM0YNZE1URVBadYCBsgftNSiB0Rlj4slLRbBURO4TkWPcn/uAkngHZjpX2a6DDM/pydihfdi6u4Z9tc6i82VVBxkoe8joO6SVIxhjuiovFcHNQB3wjPtzCLgxnkGZzldWdYD8Ab04fkgfANZVOMtJlu48wGDfXvy9BycyPGNMHLXaxOOOFrqtE2IxCaKqbNp5gItO7MfoIc6cgbXb91GYn8Pmnfvpzx7IthFDxnRXXuYR5AI/BMYCmeH9qnpWHOMynWj3wXr21QbIH5DFsH496ZXhZ+32vQDsqtpBGkGwPgJjui0vTUNPAGuAkcBPgVKc1cdMN1Fa5YwYKhjQC59PGJbTk7fW7OCx9zehB9w5BNlWERjTXXmpCAao6p+BelV9R1W/CdjVQDcSnkNQMDCLkrJqPqs8wJbqGu56eRW54owcXnugZyJDNMbEkZeKoN69/VxEviIik4D+LT3BdC2lVQcQgeE5WRRvrCIUtUj9QJyKoGRneqLCM8bEmZf5AD93U09/H/gD0Af4XlyjMh2upKy60YpiYR9vriY7I42V2/ZSdPQAeqT7qKsPEQIG+ZyK4IRRtk6AMd1VixWBm3V0lKq+AuwB2pR6WkTOBX4H+IGHVfWemMdHAPOAfm6Z29x1jk0HKimr5oqHiqkLhuiR5uOJ64oilUFJWTXvrt+JKsx5uLjBMpQ5WRkcv+IfaHkaJ44qSOybMMbETYtNQ6oaBC5vz4HdSuQB4DzgBOByETkhptgdwLOqOgm4DPjf9ryWaVnxxioOBUKoOnmEijdWRR57adnWyKqA0emnbzzzWK6YPoLCAQEkOxd8XloRjTFdkZemofdF5H9wJpNFMpCq6ketPG8asEFVNwKIyNPAhcCqqDKK09QE0BfY5jFu0waF+f0i90MKGyv3U1JWzaH6IC9+XA6AXyA9rWH6aQAO7LCso8Z0c14qghPd27uj9imtjxwaBmyJ2i4HpseUuQv4h4jcDPQCvuAhHtNG+2qDAEzK68fHW3bz/EdbeWnZNkKqhBTSfMLsqXlcMnl448Xj9++AbJtVbEx35mVmcTyXpLwceExV7xWRk4D/E5FxqhqKLiQiNwA3AIwYMSKO4XRPLy3bSv9eGZw1ZhDLtuxGgUDUyCBVZWi/no0rAXAqgsFjOy9YY0yn8zKz+CdN7VfVu5vaH2UrkBe1PdzdF+1a4Fz3eB+ISCYwENgR81pzgbkAU6ZMUYxnBw4FWLC6gq8VDufkYwbyQPoG6gIhfD5BgFBIm24SAlCFA5XWNGRMN+elaSh6ZbJMnGUrV3t43hJglIiMxKkALgOuiCmzGTgbeExExrjHr/RwbNOK9zfs5J11lXy+u4ba+hCjh/ShMD8nMiIo/MHf3JBSAGqqIVRvs4qN6ea8NA3dG70tIr8B3vDwvICI3OSW9QOPqOpKEbkbWKqq83HmJjwkIt/D6Xe4WlXtG/8RWlK6i68//CHRJ/Lnf1/FmKOcyiD6Q78wPwfKiuHtd5wVyA7thZGnOevGfvZPp1DtPowx3Vd7FpjJwmnmaZU7J+DVmH0/ibq/CjilHTGYFvx16RZia9PooaENbFkMj50H0d0yaT3h3Hvgtf9wtt+7F449yxYVN6ab8tJH8ClEPlf8QC4NRxCZJLNz/yHAmSQSAnzNDQ0FKF3UsBIACNbB6pcg6GYXCQWdclYRGNMtebkiOD/qfgCoUNVAnOIxR+hQIMiS0mpOP24g00YOICcrg+qDdc33AwwtbLzPnwZjLoSN74AGwZ8BBTPiH7wxJiG8VARHAStVdR+AiPQWkRNU9cP4hmba4+21leyrDfDNU4/m9OM8jPbJcYfjnnAhDDwe3v0VzPg+TLkaiv8IgVr46kN2NWBMN+Ylb8Afgf1R2wfcfSZJlJRV88DCDZSUVTPv/VKy0v30TPeYEmK/O0hr0pVw2g/AlwaBQ05z0J7NcPx5VgkY0815uSKQ6JE8qhoSkfZ0Mps4CCeUOxRo2M5/5SOLGySXa1b0wjNpPWDgcbB9BVSXQv1Bm0xmTArw8rVxo4jcIiLp7s93gI3xDsx4E04oF6s+Jrlcs/ZXOLfhuQKDx0HFSqhY4W5bRWBMd+elIvgWcDLOpLBwvqAb4hmU8W5qweFv/Bl+ISPN13wCuabsrwQEsgY624PHwt5yKH0PxAeDxsQncGNM0vAyoWwHzqxgk4TCVwMXnTiUb5xUALQyWzjWgR2Q1d8ZKQTOFQHAiudhwLGQbktUGtPdeZlHMA/4jqrudrdzgHvdtYtNgr20bBu9e6Rxz1cnkJnuB/BWAYTt3wG9olJIDHErgoNVMPL0DozUGJOsvHT6TghXAgCqWu2uW2w6UHgpyfC4/+jx/0CTj2X38DN/2TZOOXZApBJoswOVDXMJZQ+GrAFORWD9A8akBC8VgU9EclS1GkBE+nt8nvGopKyay+c6S0nG8olzG2ohA9P7G6ooKatu25VA2P4dMHzK4W0R6JvnVAT+jLYfzxjT5XjpLL4X+EBEfiYiPwf+BfwqvmGllr8v39ZkJQBOBdBSJQAQDHkcIdSU2KahLYsPjxha+Atn2xjTrXnpLH5cREo4vHD9JW6yONNG4eaf6OaePplpvPixs0xDODeQ4CR38omzehgiBAKhBo9Fl/E8QihW3QGoPwDZUTOQo3MPBestx5AxKcBTE4+bProSZ70ARGSEqm6Oa2TdTElZNXPciV8+HwjSYJUwvw8umzqCsUP7eu4jaDWPUGv2u5PJoq8ICmaAv4eTeM5yDBmTEryMGpqJ0zw0FGflsHychWmsJ7ENijdWUesO9XRagWLaexSG9uvJFdObXoqzXR/0rTngppeI7izOmwZXzXeuBApm2NWAMSnAyxXBz4AiYIGqThKRM4Gvxzes7ifofvsXIM3v9AAHgnrkzTtHYn9UeoloedOsAjAmhXipCOpVtUpEfCLiU9WFInJ/vAPryt5YuZ2311bSu0ca+w4FyEwXnvxwC8NzejJ7ah4nH+PM4o1u7ml3886RCKeX6GVLURqTyrxUBLtFJBt4F3hCRHbQcB1jE+WFj8q59dlPmnysct8hTj5mYOQDv9M/+GOFm4Z6DUxsHMaYhPIyfPRC4CDwPeB14DPggngG1VXV1gf55aurm308EDyCYZ7xsH8H9OwP/vRER2KMSSAvw0fD3/5DwLy2HFxEzgV+h7PE5cOqek/M47/l8LDULGCQqvZry2skk//46yfs3F9Hmk8IhbTRUNCE9AO05MCOxv0DxpiUE7cZwiLiBx4AzsHJWrpEROZHz0FQ1e9Flb8Z6LKpK174qJyXl38OOB/6s6c3PRQ04c1B0fZXWkVgjIlrqohpwAZV3QggIk/jNDM1NxntcuDOOMYTV08vOTytIhjSFoeCJo0DO2Do5ERHYYxJMI/rGbbLMGBL1Ha5u68REckHRgJvxTGeuAmFlI07DuAT2rYWQKLt/Rz2bLE0EsakOC8Tyk4B7sKZSJaG2+ytqkd3YByXAc+parCZGG7AXQxnxIjk+5a9tKyanQfq+O4XRpHu9yVfE1BTNr4LgRqnEpg305lEZnMHjElJXpqG/owzYqgEaPKDuhlbgbyo7eHuvqZcBtzY3IFUdS4wF2DKlCmtpGDrfC8t20rPdD/XzziaXj26SGLWtX9376iTTsJyChmTsrx8au1R1dfacewlwCgRGYlTAVwGXBFbSERGAznAB+14jYRbvKmK5z8qpzC/f9epBAAy+zm34recQsakOC+fXAtF5NfAC8Ch8E5V/ailJ6lqQERuAt7AGT76iJu87m5gqarOd4teBjytqkn3Tb81JWXVfP3hD6kLKos3HcGaAIlQfxB8aXD6bXD06XY1YEwK81IRTHdvo1YvQYGzWnuiqr4KvBqz7ycx23d5iCEpFW+soi7o1F+hkFK8sarrVAQVK2HQCXD6fyQ6EmNMgnmZUHZma2VS1aS8foDTe95lRgqFVayEY1qty40xKcDLqKG+OOP7T3N3vQPcrap74hlYV1B1oA6AS6fmcemUvK5zNXBgJ+zfbmsSG2MAb/MIHgH2AZe6P3uBR+MZVFfx0rJtDO7Tg19ePL7rVAJweCnKIeMSG4cxJil46SM4RlW/GrX9UxFZFqd4uox311by1poKvjL+KPzhFea7ioqVzu1gqwiMMd6uCGpE5NTwhjvBrCZ+ISW/krJqrn18CSGFN1ZVUFJWneiQ2mb7CsgeYumnjTGAtyuCbwPz3L4CAXYBV8czqGRXvLGKene0UNBNLd3lmoasf8AY4/IyamgZMFFE+rjbe+MdVLIrOnpAJL10QkcLbVnszAjuOQBqqg5PCoveF3ub2c9pGhp3SWJiNsYknWYrAhH5uqr+RURujdkPgKreF+fYktbYoX0QgaKR/fnBl0Yn5mpgy2KYdwEEag/vE79z23TKpoZW/Q2m3WATyYwxLfYR9HJvezfxkx3nuJLahh37CSnMKcpPXJNQ6SIIHGq4T4PeKgGAUMg5hjEm5TV7RaCqD7p3F6jq+9GPuR3GKWvt9n0AjB7SO3FBFMwAEQhn5hCfkzICgWA9NFgfLeZWfJZfyBgT4aWz+A9A7OolTe1LGWsr9pGR5qNgQK/WC8fL8KmQlumkiZj0De99BNH9CdYsZIyh5T6Ck4CTgdyYfoI+OEnkUtba7fs4NjebNH881/Vpxe7NTuK4SXNgytUNH7MPeGNMG7T0SZaB0xeQRsP+gb3A1+IfWvJau31fYpuFIGpS2PjExmGM6fJa6iN4B3hHRB5T1bJOjCmp7TlYz/a9tRyXLBXBoDGJjcMY0+V56SM46K5HMBbIDO9U1ZRMXblmuzON4viEVwSfQs5I6JHSA7iMMR3ASyP3E8AanMXlfwqU4qw+lpLWViTBiCFwrggsaZwxpgN4qQgGqOqfgXpVfUdVv4mHRWm6q/fW76RHmo9t1QlMt1R3EKo+s6RxxpgO4aUiqHdvPxeRr4jIJKB/HGNKWiVl1by5uoJDgRBz/vxh4pLN7VgNqOULMsZ0CC8Vwc/dhHPfB34APAx8L65RJanijVWR+Vv1ASfZXEKsftm5DXmcRWyMMS1otSJQ1VdUdY+qrlDVM1W1MGrh+RaJyLkislZENojIbc2UuVREVonIShF5sq1voDNFJ5dLWLK5LYvhg98791/8lrNtjDFHoKUJZX/AyUvQJFW9paUDi4gfeAA4BygHlojIfFVdFVVmFHA7cIqqVovIoDbG36kK83PI7uFn1ODe3PGVExKTZ6h00eErgWCds20TyIwxR6ClK4KlQAnOkNHJwHr350ScyWatmQZsUNWNqloHPA1cGFPmeuABVa0GUNUdbYo+AeqCyrSR/ROXbC4/vEaQWL4gY0yHaGlC2TwAEfk2cKqqBtztPwFe0lYOA7ZEbZcD02PKHOce832ctBV3qerrnqPvZMGQUhcI0TM9gRk2+g5zbo8/D079nl0NGGOOmJcJZTk4+YV2udvZ7r6Oev1RwBnAcOBdERmvqrujC4nIDcANACNGjOigl267mnqnSSYrI4EVwXZ34flTvmOVgDGmQ3gZNXQP8LGIPCYi84CPgF96eN5WIC9qe7i7L1o5MF9V61V1E7AOp2JoQFXnquoUVZ2Sm5vr4aXjo6bOqQh6ZnipP+Okwq0IBp2QuBiMMd2Kl1FDj+I06bwIvACcFG42asUSYJSIjBSRDOAyIHa00d9wrgYQkYE4TUUbvQbf2SIVQSKbhipWQr98yOyTuBiMMd1KsxWBiIx2bycDQ3Ha+7cAQ919LXL7FG4C3gBWA8+q6koRuVtEZrrF3gCqRGQVsBD4D1VN0OD81iVF01DFCptRbIzpUC21cXwfZ1TPvU08pnhIM6GqrwKvxuz7SdR9BW51f5LewboAkMArgvoaqNoAYy9OzOsbY7qllkYNXe/entl54SS3w30ECaoIKteAhiy1hDGmQ7U0oeySlp6oqi90fDjJLdw0lLArgvCIIWsaMsZ0oJaahi5o4THF6ThOKQfrEtxHULES0rOcdQiMMaaDtNQ0dE1nBtIVhK8IMhN1RVD2L+iZA1uX2hwCY0yH8TQgXkS+QuMVyu6OV1DJqiaRVwSbP4Ttnzj3582Eq+ZbZWCM6RCtziNwU0rMBm4GBJgF5Mc5rqQU6SNIREWw7rXD98PJ5owxpgN4mVl8sqpeCVSr6k+Bk3BzBKWacB9BZloCKoKsgc6t+CzZnDGmQ3lpGgqvyXhQRIYCVcBR8QspedXWB+mZ7sfnk85/8WCdczvjBzDqHGsWMsZ0GC8VwSsi0g/4NU6eIQUeimdQyepgXSBxcwgqVkLfEXDWjxPz+saYbqvVikBVf+befV5EXgEyVXVPfMNKTjV1CUxBXbHSJpIZY+LCS2fxchH5kYgco6qHUrUSAKipT9AVQX0t7FwHQ2wimTGm43npLL4ACADPisgSEfmBiCRuUYAEOlgXTMzQ0Z1rQYN2RWCMiQsvaajLVPVXqloIXAFMADbFPbIkVFMXTMxksoqVzq2lljDGxIHXCWX5OHMJZgNB4IfxDCpZ1dQH6d/Ly3LNHWz7CkjrCf2P7vzXNsZ0e61WBCLyIZAOPAvMUtWkXTgm3mrqgvTsl4grghUwaAz4ErgOgjGm2/JyRXClqq6NeyRdwMG6YMudxVsWOzN+ew6Amqrmb8OTwbyUzT8Vtn3sXA1sWWzzB4wxHc7L8FGrBFzhCWVNWvsaPHU5zjSLOPj8E8sxZIyJCy+jhoyrxVFDn/6VuFUC4BzbcgwZY+LAU2exAVWlpj5Iz4xmTpm/h3vHB4Rw8vNp41vxgS/N2Q7Wey8bCliOIWNMXLS5IhCRKcA2Vd3moey5wO8AP/Cwqt4T8/jVOKkrtrq7/kdVH25rTJ2htj4EtLA6WU019MuHwqs6to8gumzBDGsWMsZ0uPZcEdwMTBCRdao6u7lCIuIHHgDOAcqBJSIyX1VXxRR9RlVvakccnSq8cH2zTUMVKyBvOsz4vveDtuVD3SoAY0yctLkiUNWrAESkdytFpwEbwsNNReRp4EIgtiLoElpcr7hmN+zZAlOv7dygjDGmA3jJNfSCiHxFRBqUVdV9rTx1GLAlarvc3Rfrq24+o+dEJK/ViNuppKyaBxZuoKSsul3PD69O1uTw0R1u3WYzf40xXZCXUUP/i5NaYr2I3CMix3fg678MFKjqBOBNYF5ThUTkBhFZKiJLKysr2/wiJWXVXPFQMb95Yy1zHi5uV2XQ4hXB9hXOreUCMsZ0QV5yDS1Q1TnAZKAUWCAi/xKRa0QkvYWnbgWiv+EP53CncPjYVap6yN18GChsJoa5qjpFVafk5ua2FnIjxRurqAuEUKA+EKJ4Y1Wbj3GwpfWKK1ZAz/7QOyXX6zHGdHGe5hGIyADgauA64GOckUCTcb7FN2cJMEpERopIBnAZMD/muNGfnDOB1Z4jb4OioweQ5ndWFUvz+yg6ekCbjxG+IshssiJw1wqQBKxcZowxR8hLH8GLwCIgC7hAVWeq6jOqejOQ3dzzVDUA3AS8gfMB/6yqrhSRu0VkplvsFhFZKSKfALfgVDYdrjA/h+9/0WnR+tmFYynMz2nzMWqauyIIBZ0+AusfMMZ0UV5GDf1eVRc29YCqTmnpiar6KvBqzL6fRN2/HbjdQwxHbGqB8+E/qE9mu54frgj67vwY1i89PM4/FIT6g5CR1WGxGmNMZ/JSEZwgIh+r6m4AEckBLlfV/41rZB0sJ8tJH119sK5dzz9YH2SyrGPICz93ZvnG+tf/wHHn2nh/Y0yX46WP4PpwJQCgqtXA9XGLKE7C6whUH6hv1/Nr64IU+VY3XQmAs9/yABljuiAvFYFf5HAvqDtjOAGrsxyZPpnp+OQIrgjqghSHxsTsdU+L+CwPkDGmy/LSNPQ68IyIPOhu/5u7r0vx+YScrAx2HWhv01CAjf4C56P/mLNhzMzGOYGsWcgY0wV5qQj+E+fD/9vu9ps4Y/67nJxeGe2+IqitCzIszZ1MPf5rcOIVHRiZMcYkjpeFaULAH92fLq3/kVwR1AUZlr4P6oFegzo2MGOMSSAvaxaPAv4fcAIQGXupql1uJfWcXumU7jzYrufW1AcZ4t/rVATZbZ/dbIwxycpLZ/GjOFcDAeBM4HHgL/EMKl7698pgVzubhmrqggzy7XU27IrAGNONeKkIeqrqPwFR1TJVvQv4SnzDio9+WRlUH6hDte1LStbUB8mVcEUwsIMjM8aYxPHSWXzITUG9XkRuwkkc12xqiWTWPyuDQEjZdyhAn8yW8uU1drAuyEB2O8nl/G17rjHGJDMvVwTfwckzdAtOdtCvA1fFM6h4yYlMKmt781BtfZD+7IbswR0clTHGJFaLVwTu5LHZqvoDYD9wTadEFSf9eznf5KsP1pPfxgSkB+uC9NXd1lFsjOl2WrwiUNUgcGonxRJ3kXxD7bgiOFgXpG+w2jqKjTHdjpc+go9FZD7wV+BAeKeqvhC3qOIknG+oPXMJDhwKkJW2i4pQH6xxyBjTnXjpI8gEqoCzgAvcn/PjGVS8RPoI2jiEtKR0F9QfoKfW8JcVNe1e99gYY5KRl5nFXbpfIFrvHmmk+aTNVwQL11YyUPYAUBHsTfHGqnYtbmOMMcnIy8ziR4FGA+9V9ZtxiSiORKRd+YayM9PIxakIqn05zG7HUpfGGJOsvPQRvBJ1PxO4GNgWn3Dirz35hqoP1EVmFX/vohmcYFcDxphuxEvT0PPR2yLyFPBe3CKKs5xe6W1enGZJ6S6+2L8e9sEJo46JU2TGGJMYXjqLY40CPI2hFJFzRWStiGwQkdtaKPdVEVERaXEN5I6Qk9W2fEO19UE+3bqHE/rUOjt62TwCY0z34qWPYB8N+wi246xR0Nrz/MADwDlAObBEROar6qqYcr1xZi9/2Ia42y2nV0ab5hEsL99DfVAZmXkAeuZYegljTLfjpWmodzuPPQ3YoKobAUTkaeBCYFVMuZ8B/w38Rztfp036Z2Wwu6aeUEjx+aTV8ktKdwEw2LfHJpMZY7qlVpuGRORiEekbtd1PRC7ycOxhwJao7XJ3X/SxJwN5qvp3b+EeuZxeGQRDyr7aZhahj7G0dBfHDsomo7YKsq0iMMZ0P15GDd2pqi+GN1R1t4jcCfztSF7YzWh6H3C1h7I3ADcAjBgx4khelr01TrPQog2VHNW3J8Ubq8jJcoaUxt5OH9mfDzft4tjcbA5VldKj9wDYstjWJjbGdCteKoKmrhq8PG8rkBe1PdzdF9YbGAe8LSIAQ4D5IjJTVZdGH0hV5wJzAaZMmdL2xQRcJWXV/PHtjQDc9OTHnp+Xtm0JGRnb0YMVyLyZcNV8qwyMMd2Gl1FDS0XkPhE5xv25Dyjx8LwlwCgRGSkiGcBlwPzwg6q6R1UHqmqBqhYAxUCjSqAjFW+sIhAKtfl5p/hWIAKCQrAOShfFITpjjEkMLxXBzUAd8AzwNFAL3Njak1Q1ANwEvAGsBp5V1ZUicreIzGx/yO1XdPQAMtJ8+AUy/EJGmi9yAiTm1hdVZpWOBEAR8GdAwYzODt0YY+JG2rNsYyJNmTJFly5t/0VDSVk1xRurKHLTRLTURxAus2ZFCXOWfBXGXgxF/27NQsaYLkdESlS1yblaXuYRvAnMUtXd7nYO8LSqfqlDo+wkhfk5DRLGeUkeV+jPcRq6Jl5ulYAxptvx0jQ0MFwJAKhqNR5nFncbtbud2x59EhqGMcbEg5eKICQikTGbIpJPE9lIu7VDTsI5Mvu2XM4YY7ogL8NAfwy8JyLv4PSlzsAd058yasMVgV0RGGO6Hy8pJl53ZwAXubu+q6o74xtWkql11iKwKwJjTHfk5YoAIAjswFmP4AQRQVXfjV9YSebQXhAfZGQnOhJjjOlwXkYNXYeTHXQ4sAznyuADnDWMU0PtHqejWFpPUmdMZ6qvr6e8vJza2tpEh2KSRGZmJsOHDyc93XumZC9XBN8BpgLFqnqmiIwGftnOGLum2r3WP2CSUnl5Ob1796agoACxLyopT1WpqqqivLyckSNHen6el1FDtapaCyAiPVR1DXB8O+Psmmr3WP+ASUq1tbUMGDDAKgEDOOuyDxgwoM1XiF6uCMpFpB9OttE3RaQaKGtzhF3Zob3QwyoCk5ysEjDR2vP74GXU0MXu3btEZCHQF3i9za/UldXugX5Hlv7aGGOSlddRQwCo6jvxCiSp1e61piFjEiwQCJCW1qaPLONRexavTz2H9lh6CdNtlJRV88DCDZSUVXfYMS+66CIKCwsZO3Ysc+fOBeD1119n8uTJTJw4kbPPPhuA/fv3c8011zB+/HgmTJjA888/D0B29uGh2c899xxXX301AFdffTXf+ta3mD59Oj/84Q9ZvHgxJ510EpMmTeLkk09m7dq1AASDQX7wgx8wbtw4JkyYwB/+8AfeeustLrrooshx33zzTS6++GJMY1a9tiYUsisC0yX89OWVrNq2t8Uy+2rrWbN9HyF1Uq2PHtKb3pnNDzM8YWgf7rxgbKuv/cgjj9C/f39qamqYOnUqF154Iddffz3vvvsuI0eOZNcuZ+3vn/3sZ/Tt25dPP/0UgOrq1iuj8vJy/vWvf+H3+9m7dy+LFi0iLS2NBQsW8KMf/Yjnn3+euXPnUlpayrJly0hLS2PXrl3k5OTw7//+71RWVpKbm8ujjz7KN7/5zVZfLxVZRdCauv2A2vBR0y3srQ0QcjOFhdTZbqki8Or3v/89L77orGi7ZcsW5s6dy2mnnRYZwti/f38AFixYwNNPPx15Xk5O69l/Z82ahd/vB2DPnj1cddVVrF+/HhGhvr4+ctxvfetbkaaj8Ot94xvf4C9/+QvXXHMNH3zwAY8//vgRv9fuyCqC1lh6CdNFePnmXlJWzZyHi6kPhEhP8/G7yyZ5SsXekrfffpsFCxbwwQcfkJWVxRlnnMGJJ57ImjVrPB8jeqRL7NDHXr16Re7/13/9F2eeeSYvvvgipaWlnHHGGS0e95prruGCCy4gMzOTWbNmWR9DM6yPoDXhzKPWR2C6gcL8HJ64rohbv3g8T1xXdMSVADjf0nNycsjKymLNmjUUFxdTW1vLu+++y6ZNmwAiTUPnnHMODzzwQOS54aahwYMHs3r1akKhUOTKornXGjZsGACPPfZYZP8555zDgw8+SCAQaPB6Q4cOZejQofz85z/nmmuuOeL32l1ZRdAauyIw3Uxhfg43nnlsh1QCAOeeey6BQIAxY8Zw2223UVRURG5uLnPnzuWSSy5h4sSJzJ49G4A77riD6upqxo0bx8SJE1m4cCEA99xzD+effz4nn3wyRx11VLOv9cMf/pDbb7+dSZMmRT70Aa677jpGjBjBhAkTmDhxIk8++WTksTlz5pCXl8eYMWM65P12Rym3VGWbrX0dnpoN178Fwwo773WN8WD16tX2AdeKm266iUmTJnHttdcmOpRO09TvRUtLVcb1ikBEzhWRtSKyQURua+Lxb4nIpyKyTETeE5ET4hlPu0SuCPolNAxjTNsVFhayfPlyvv71ryc6lKQWt54TEfEDDwDnAOXAEhGZr6qrooo9qap/csvPBO4Dzo1XTO1ifQTGdFklJSWJDqFLiOcVwTRgg6puVNU64GngwugCqho96LkXybgEZni9Yhs+aozppuI5lmoYsCVquxyYHltIRG4EbgUySMY1Dmr3QlompPVIdCTGGBMXCR81pKoPqOoxwH8CdzRVRkRuEJGlIrK0srKycwM8tNeahYwx3Vo8K4KtQF7U9nB3X3OeBi5q6gFVnauqU1R1Sm5ubsdF6IWtRWCM6ebiWREsAUaJyEgRyQAuA+ZHFxCRUVGbXwHWxzGe9rHVyYzpUOEEc9u2beNrX/tak2XOOOMMWhsmfv/993Pw4MHI9pe//GV2797dYXGmkrhVBKoaAG4C3gBWA8+q6koRudsdIQRwk4isFJFlOP0EV8UrnnazKwJj4mLo0KE899xz7X5+bEXw6quv0q9fvw6IrHOoKqFQKNFhAHHuI1DVV1X1OFU9RlV/4e77iarOd+9/R1XHquqJqnqmqq6MZzztYn0EprvZshgW3evcHqHbbrutQcqIu+66i9/85jfs37+fs88+m8mTJzN+/HheeumlRs8tLS1l3LhxANTU1HDZZZcxZswYLr74YmpqaiLlvv3tbzNlyhTGjh3LnXfeCThJ7rZt28aZZ57JmWeeCUBBQQE7d+4E4L777mPcuHGMGzeO+++/P/J6Y8aM4frrr2fs2LF88YtfbPA6YS+//DLTp09n0qRJfOELX6CiogJoPoV2U+m2w+chbNy4cZSWllJaWsrxxx/PlVdeybhx49iyZUuT7w9gyZIlnHzyyUycOJFp06axb98+TjvtNJYtWxYpc+qpp/LJJ594/N9qnmVgao1dEZiu4rXbYPunLZc5tBcqVoCGQHwweFzLX3SGjIfz7mn24dmzZ/Pd736XG2+8EYBnn32WN954g8zMTF588UX69OnDzp07KSoqYubMmc0uo/jHP/6RrKwsVq9ezfLly5k8eXLksV/84hf079+fYDDI2WefzfLly7nlllu47777WLhwIQMHDmxwrJKSEh599FE+/PBDVJXp06dz+umnk5OTw/r163nqqad46KGHuPTSS3n++ecbTTY79dRTKS4uRkR4+OGH+dWvfsW9997bZArtysrKJtNtt2T9+vXMmzePoqKiZt/f6NGjmT17Ns888wxTp05l79699OzZk2uvvZbHHnuM+++/n3Xr1lFbW8vEiRNbfc3WJHzUUNKzPgLTndTucSoBcG7DM+fbadKkSezYsYNt27bxySefkJOTQ15eHqrKj370IyZMmMAXvvAFtm7dGvlm3ZR333038oE8YcIEJkyYEHns2WefZfLkyUyaNImVK1eyatWq5g4DwHvvvcfFF19Mr169yM7O5pJLLmHRokUAjBw5khNPPBFwZh2XlpY2en55eTlf+tKXGD9+PL/+9a9ZudJpqFiwYEGkwgMnhXZxcXGT6bZbkp+fH6kEmnt/a9eu5aijjmLq1KkA9OnTh7S0NGbNmsUrr7xCfX09jzzySGQBnyNlVwQtCdRBoMauCEzX0MI394gti2HeTAjWgT8Dvvow5E07opedNWsWzz33HNu3b48kl3viiSeorKykpKSE9PR0CgoKGqWX9mLTpk385je/YcmSJeTk5HD11Ve36zhhPXocng/k9/ubbBq6+eabufXWW5k5cyZvv/02d911V5tfJy0trUH7f3TM0Wm12/r+srKyOOecc3jppZd49tlnO2zmtF0RtCSSXsIqAtNN5E2Dq+bDWT92bo+wEgCneejpp5/mueeeY9asWYCTLnrQoEGkp6ezcOFCysrKWjzGaaedFskYumLFCpYvXw7A3r176dWrF3379qWiooLXXnst8pzevXuzb9++RseaMWMGf/vb3zh48CAHDhzgxRdfZMaMGZ7fT3Sq63nz5kX2N5VCu6ioqMl02wUFBXz00UcAfPTRR5HHYzX3/o4//ng+//xzlixZAsC+ffsi2Vavu+46brnlFqZOneppYR8vUueKYMtiKF0EPQdATRUUuL8Y0ftib3Ocyz3K/gVDT+yQPxpjEi5vWof+Lo8dO5Z9+/YxbNiwSArpOXPmcMEFFzB+/HimTJnC6NGjWzzGt7/9ba655hrGjBnDmDFjKCx0Mv1OnDiRSZMmMXr0aPLy8jjllFMiz7nhhhs499xzGTp0aCSdNcDkyZO5+uqrmTbNeY/XXXcdkyZNarIZqCl33XUXs2bNIicnh7POOivyIX7HHXdw4403Mm7cOPx+P3feeSeXXHJJJN12KBRi0KBBvPnmm3z1q1/l8ccfZ+zYsUyfPp3jjjuuyddq7v1lZGTwzDPPcPPNN1NTU0PPnj1ZsGAB2dnZFBYW0qdPnw5dXyE10lBvWQyPfhlC9TEPCN7SG/mcFBMd9A3KmI5iaahTz7Zt2zjjjDNYs2YNPl/TjTpJlYY6aZQuglCwiQe8VoIhp021dFFHRmWMMW3y+OOPM336dH7xi180Wwm0R2o0DRXMcL7RBw4B7rA5XxogEKx39kWuDtzb6DKhgNOxVuC9ndEYYzralVdeyZVXXtnhx02NiiDcQdbWPoLoMgUzrFnIGNMtpUZFAM13kHn5cLcKwCQxVW12opZJPe3p902NPgJjuqnMzEyqqqra9cdvuh9VpaqqiszMzDY9L3WuCIzphoYPH055eTmdvk6HSVqZmZkMHz68Tc+xisCYLiw9PT2S3sCY9rKmIWOMSXFWERhjTIqzisAYY1Jcl0sxISKVQMsZrJo3ENjZgeHEW1eLF7pezBZvfFm88dWWePNVtclF37tcRXAkRGRpc7k2klFXixe6XswWb3xZvPHVUfFa05AxxqQ4qwiMMSbFpVpFMDfRAbRRV4sXul7MFm98Wbzx1SHxplQfgTHGmMZS7YrAGGNMjJSpCETkXBFZKyIbROS2RMcTS0TyRGShiKwSkZUi8h13f38ReVNE1ru3HbNIaQcREb+IfCwir7jbI0XkQ/c8PyMiGYmOMUxE+onIcyKyRkRWi8hJyXx+ReR77u/CChF5SkQyk+38isgjIrJDRFZE7WvynIrj927sy0VkcpLE+2v3d2K5iLwoIv2iHrvdjXetiHwpGeKNeuz7IqIiMtDdbvf5TYmKQET8wAPAecAJwOUickJio2okAHxfVU8AioAb3RhvA/6pqqOAf7rbyeQ7wOqo7f8GfquqxwLVwLUJiappvwNeV9XRwEScuJPy/IrIMOAWYIqqjgP8wGUk3/l9DDg3Zl9z5/Q8YJT7cwPwx06KMdpjNI73TWCcqk4A1gG3A7h/f5cBY93n/K/7WdKZHqNxvIhIHvBFYHPU7naf35SoCIBpwAZV3aiqdcDTwIUJjqkBVf1cVT9y7+/D+ZAahhPnPLfYPOCihATYBBEZDnwFeNjdFuAs4Dm3SNLEKyJ9gdOAPwOoap2q7iaJzy9OUsieIpIGZAGfk2TnV1XfBXbF7G7unF4IPK6OYqCfiBzVKYG6mopXVf+hqgF3sxgIp+68EHhaVQ+p6iZgA85nSadp5vwC/Bb4IQ3X2233+U2VimAYsCVqu9zdl5REpACYBHwIDFbVz92HtgODExVXE+7H+WUMudsDgN1Rf1TJdJ5HApXAo25T1sMi0oskPb+quhX4Dc43vs+BPUAJyXt+ozV3TrvC3+E3gdfc+0kZr4hcCGxV1U9iHmp3vKlSEXQZIpINPA98V1X3Rj+mzhCvpBjmJSLnAztUtSTRsXiUBkwG/qiqk4ADxDQDJdn5zcH5hjcSGAr0ookmgmSXTOe0NSLyY5wm2icSHUtzRCQL+BHwk448bqpUBFuBvKjt4e6+pCIi6TiVwBOq+oK7uyJ8eefe7khUfDFOAWaKSClOU9tZOG3w/dymDEiu81wOlKvqh+72czgVQ7Ke3y8Am1S1UlXrgRdwznmynt9ozZ3TpP07FJGrgfOBOXp4TH0yxnsMzpeDT9y/veHARyIyhCOIN1UqgiXAKHfERQZOB9D8BMfUgNu+/mdgtareF/XQfOAq9/5VwEudHVtTVPV2VR2uqgU45/MtVZ0DLAS+5hZLpni3A1tE5Hh319nAKpL0/OI0CRWJSJb7uxGONynPb4zmzul84Ep3dEsRsCeqCSlhRORcnCbOmap6MOqh+cBlItJDREbidMIuTkSMYar6qaoOUtUC92+vHJjs/n63//yqakr8AF/GGRHwGfDjRMfTRHyn4lxCLweWuT9fxml3/yewHlgA9E90rE3Efgbwinv/aJw/lg3AX4EeiY4vKs4TgaXuOf4bkJPM5xf4KbAGWAH8H9Aj2c4v8BROH0a9+6F0bXPnFBCc0XufAZ/ijIhKhng34LSth//u/hRV/sduvGuB85Ih3pjHS4GBR3p+bWaxMcakuFRpGjLGGNMMqwiMMSbFWUVgjDEpzioCY4xJcVYRGGNMirOKwJhOJCJniJup1ZhkYRWBMcakOKsIjGmCiHxdRBaLyDIReVCcdRf2i8hv3TUC/ikiuW7ZE0WkOCqffTj//rEiskBEPhGRj0TkGPfw2XJ4XYQn3JnDxiSMVQTGxBCRMcBs4BRVPREIAnNwEr8tVdWxwDvAne5THgf+U5189p9G7X8CeEBVJwIn48wQBSez7Hdx1sY4GieHkDEJk9Z6EWNSztlAIbDE/bLeEydxWgh4xi3zF+AFd52Dfqr6jrt/HvBXEekNDFPVFwFUtRbAPd5iVS13t5cBBcB7cX9XxjTDKgJjGhNgnqre3mCnyH/FlGtvfpZDUfeD2N+hSTBrGjKmsX8CXxORQRBZgzcf5+8lnPnzCuA9Vd0DVIvIDHf/N4B31FllrlxELnKP0cPNJW9M0rFvIsbEUNVVInIH8A8R8eFkfrwRZzGbae5jO3D6EcBJtfwn94N+I3CNu/8bwIMicrd7jFmd+DaM8cyyjxrjkYjsV9XsRMdhTEezpiFjjElxdkVgjDEpzq4IjDEmxVlFYIwxKc4qAmOMSXFWERhjTIqzisAYY1KcVQTGGJPi/j/qPlbrerIlWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fa96c58b1d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fa9b8dc6450>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fa9b8dc6810>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_12'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put weights and biases of the first hidden layer in w1 and b1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1 = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09064305, -0.11489491, -0.10372677,  0.06981694, -0.13074689,\n",
       "        -0.10586016,  0.19037473,  0.14632624, -0.0010767 ,  0.26565212,\n",
       "         0.06161043, -0.04748669,  0.11605041,  0.2173242 , -0.15520531,\n",
       "         0.16090067, -0.20253426, -0.16671976,  0.25059748,  0.05865558,\n",
       "        -0.0685889 , -0.0311309 ,  0.0562751 ,  0.24179825,  0.04450311,\n",
       "        -0.14236248,  0.13820457, -0.10370433, -0.17282233,  0.08219323,\n",
       "        -0.06025746,  0.14881234, -0.19861673, -0.2104568 ,  0.08800248,\n",
       "        -0.05025969, -0.14499196,  0.06244656, -0.18853037,  0.13453819,\n",
       "        -0.12003261,  0.27340198, -0.11214349,  0.07274374, -0.22971512,\n",
       "         0.072861  , -0.12662315, -0.12996174,  0.19232665,  0.17892197,\n",
       "         0.09753171,  0.07991367,  0.03764449, -0.01948798, -0.19422051,\n",
       "        -0.08717385,  0.21986903,  0.24928924,  0.07068825, -0.22466168,\n",
       "        -0.1885413 ,  0.1313433 , -0.06929348, -0.17149362,  0.22830085,\n",
       "         0.08197086,  0.11383541, -0.23366289, -0.14908054,  0.12261952,\n",
       "         0.2030277 , -0.22985193,  0.03000009, -0.0392168 , -0.05485973,\n",
       "         0.09839846, -0.23615961, -0.171516  ,  0.04672317,  0.17652279,\n",
       "         0.0737428 ,  0.07009134, -0.04238081,  0.00544113,  0.02672652,\n",
       "        -0.02147609, -0.17513515, -0.00220573, -0.17567083, -0.16093373,\n",
       "         0.13129465,  0.15568924,  0.21103257, -0.0497447 , -0.12984285,\n",
       "        -0.19998764,  0.07487345,  0.0022801 , -0.1332461 ,  0.16535611],\n",
       "       [ 0.03975117,  0.0396716 ,  0.00836456,  0.28848985,  0.12884012,\n",
       "         0.22328654, -0.13400283, -0.09421772, -0.03223951,  0.15698542,\n",
       "        -0.15938121, -0.05609667,  0.25999618,  0.24878547, -0.08069588,\n",
       "        -0.27426526,  0.01646239,  0.08272421,  0.2671689 ,  0.20812961,\n",
       "         0.03826314,  0.29811016, -0.2210875 ,  0.00116646, -0.11400729,\n",
       "        -0.02121946, -0.23706824,  0.02817026,  0.17250353, -0.292183  ,\n",
       "         0.06134227, -0.33213514,  0.24056298, -0.00990756, -0.21779841,\n",
       "        -0.06731072,  0.01560059,  0.24206233,  0.06195745, -0.09942289,\n",
       "         0.16715744, -0.09116008,  0.22172439, -0.2383499 ,  0.09237468,\n",
       "         0.19267541, -0.14037701, -0.2371225 , -0.1322917 ,  0.04444443,\n",
       "        -0.16635841, -0.12039243,  0.31596696,  0.02859266,  0.15970114,\n",
       "        -0.12071645,  0.01777116,  0.10164354,  0.22869183,  0.09001422,\n",
       "        -0.20341949,  0.04952862,  0.0091227 , -0.18223213,  0.28747278,\n",
       "         0.16372892,  0.08727659, -0.12108919, -0.20991631,  0.11363278,\n",
       "        -0.01491317,  0.04366064, -0.01846943,  0.06939098, -0.236719  ,\n",
       "         0.05642977,  0.19536781, -0.11255832,  0.17264614,  0.15849434,\n",
       "        -0.1684488 ,  0.31742126, -0.10086328, -0.15637738,  0.03851807,\n",
       "        -0.01302092, -0.06518525, -0.10205211, -0.05411373,  0.0957582 ,\n",
       "        -0.2707967 ,  0.25540614, -0.06330168,  0.09388109, -0.07262617,\n",
       "        -0.14548925,  0.31850252, -0.21106991, -0.00269048, -0.17606245]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.19809586,  0.        ,\n",
       "        0.        ,  0.187162  , -0.20100968,  0.        , -0.15604047,\n",
       "        0.26290467,  0.        , -0.214255  , -0.19127136,  0.        ,\n",
       "        0.21135508,  0.        ,  0.        , -0.19935685, -0.21355788,\n",
       "        0.        , -0.1577891 ,  0.252113  ,  0.23028462,  0.14339074,\n",
       "        0.        ,  0.2274552 ,  0.        ,  0.        ,  0.21671037,\n",
       "        0.        ,  0.26528746,  0.        ,  0.        ,  0.25999805,\n",
       "        0.        ,  0.        , -0.20870191,  0.        ,  0.05685798,\n",
       "        0.        , -0.09756944,  0.        ,  0.23580328,  0.        ,\n",
       "       -0.2166484 ,  0.        ,  0.        ,  0.19858375,  0.19617358,\n",
       "        0.2562645 ,  0.26897195, -0.20158044, -0.00655872,  0.        ,\n",
       "        0.        ,  0.13562123, -0.18530123, -0.17761968,  0.        ,\n",
       "        0.        ,  0.21349111,  0.        ,  0.        , -0.18260404,\n",
       "       -0.19474867, -0.1997281 ,  0.        ,  0.        , -0.18007027,\n",
       "       -0.18605034,  0.        ,  0.15010712,  0.        ,  0.        ,\n",
       "       -0.19342063,  0.        ,  0.        , -0.16431788,  0.14637458,\n",
       "       -0.05968393, -0.2200875 ,  0.        , -0.00586191,  0.21504612,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.23674674, -0.20194162, -0.14087464, -0.0059599 ,  0.        ,\n",
       "        0.        , -0.20216776,  0.        ,  0.        ,  0.17525882],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can save the model and then load it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"iris_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = keras.models.load_model(\"iris_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 10,703\n",
      "Trainable params: 10,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a larger dataset = the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the images to 0 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now, let's use 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[::10]\n",
    "X_test = X_test[::10]\n",
    "\n",
    "y_train = y_train[::10]\n",
    "y_test = y_test[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Let's build a NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# We need to flatten the 2d input arrays to 1d arrays.\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "# Add a hidden layer having 1000 neurons and ReLU.\n",
    "model.add(keras.layers.Dense(1000, activation=\"relu\"))\n",
    "\n",
    "# Add another hidden layer having 1000 neurons and ReLU.\n",
    "model.add(keras.layers.Dense(1000, activation=\"relu\"))\n",
    "\n",
    "# Add an output layer having \"softmax\" activation function. How many neurons do you need for this layer?\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Print out the model summary and make sure things are correctly set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model. Let's first try Stochastic Gradient Descent with learning rate of 1.0e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Train the model using 100 epochs and 20 % of the data in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9838335560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9838335560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "139/150 [==========================>...] - ETA: 0s - loss: 2.3038 - accuracy: 0.1289WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f98687fd4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f98687fd4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 2.3011 - accuracy: 0.1324 - val_loss: 2.2125 - val_accuracy: 0.2550\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2.1743 - accuracy: 0.3288 - val_loss: 2.1017 - val_accuracy: 0.4792\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 2.0587 - accuracy: 0.5727 - val_loss: 1.9945 - val_accuracy: 0.6050\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.9551 - accuracy: 0.6353 - val_loss: 1.8873 - val_accuracy: 0.6642\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.8378 - accuracy: 0.6803 - val_loss: 1.7798 - val_accuracy: 0.6917\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.7199 - accuracy: 0.7254 - val_loss: 1.6712 - val_accuracy: 0.7208\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.6198 - accuracy: 0.7430 - val_loss: 1.5653 - val_accuracy: 0.7408\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.5020 - accuracy: 0.7615 - val_loss: 1.4620 - val_accuracy: 0.7508\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.4014 - accuracy: 0.7739 - val_loss: 1.3658 - val_accuracy: 0.7608\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.3043 - accuracy: 0.7901 - val_loss: 1.2752 - val_accuracy: 0.7708\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.2205 - accuracy: 0.7888 - val_loss: 1.1936 - val_accuracy: 0.7783\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.1409 - accuracy: 0.8020 - val_loss: 1.1203 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.0928 - accuracy: 0.7989 - val_loss: 1.0560 - val_accuracy: 0.7992\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 1.0046 - accuracy: 0.8175 - val_loss: 0.9981 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.9515 - accuracy: 0.8155 - val_loss: 0.9462 - val_accuracy: 0.8117\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.9037 - accuracy: 0.8262 - val_loss: 0.9021 - val_accuracy: 0.8150\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.8529 - accuracy: 0.8428 - val_loss: 0.8611 - val_accuracy: 0.8208\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.8273 - accuracy: 0.8341 - val_loss: 0.8256 - val_accuracy: 0.8242\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7870 - accuracy: 0.8403 - val_loss: 0.7941 - val_accuracy: 0.8275\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7554 - accuracy: 0.8437 - val_loss: 0.7658 - val_accuracy: 0.8358\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7277 - accuracy: 0.8492 - val_loss: 0.7386 - val_accuracy: 0.8383\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.8484 - val_loss: 0.7163 - val_accuracy: 0.8408\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.8535 - val_loss: 0.6944 - val_accuracy: 0.8450\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.8529 - val_loss: 0.6746 - val_accuracy: 0.8492\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6542 - accuracy: 0.8498 - val_loss: 0.6574 - val_accuracy: 0.8517\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6512 - accuracy: 0.8479 - val_loss: 0.6420 - val_accuracy: 0.8567\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6321 - accuracy: 0.8522 - val_loss: 0.6264 - val_accuracy: 0.8575\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.8621 - val_loss: 0.6123 - val_accuracy: 0.8558\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.8597 - val_loss: 0.5987 - val_accuracy: 0.8617\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5711 - accuracy: 0.8649 - val_loss: 0.5873 - val_accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5482 - accuracy: 0.8699 - val_loss: 0.5762 - val_accuracy: 0.8642\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5406 - accuracy: 0.8734 - val_loss: 0.5647 - val_accuracy: 0.8642\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5301 - accuracy: 0.8718 - val_loss: 0.5551 - val_accuracy: 0.8675\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5427 - accuracy: 0.8715 - val_loss: 0.5460 - val_accuracy: 0.8675\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5253 - accuracy: 0.8679 - val_loss: 0.5379 - val_accuracy: 0.8675\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5133 - accuracy: 0.8701 - val_loss: 0.5292 - val_accuracy: 0.8650\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5026 - accuracy: 0.8728 - val_loss: 0.5213 - val_accuracy: 0.8692\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.8746 - val_loss: 0.5144 - val_accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4903 - accuracy: 0.8758 - val_loss: 0.5071 - val_accuracy: 0.8725\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.8833 - val_loss: 0.5005 - val_accuracy: 0.8733\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4645 - accuracy: 0.8819 - val_loss: 0.4942 - val_accuracy: 0.8742\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4487 - accuracy: 0.8888 - val_loss: 0.4883 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8830 - val_loss: 0.4827 - val_accuracy: 0.8733\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.8844 - val_loss: 0.4775 - val_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4490 - accuracy: 0.8883 - val_loss: 0.4722 - val_accuracy: 0.8792\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8917 - val_loss: 0.4667 - val_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4389 - accuracy: 0.8951 - val_loss: 0.4622 - val_accuracy: 0.8792\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8979 - val_loss: 0.4570 - val_accuracy: 0.8808\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4397 - accuracy: 0.8881 - val_loss: 0.4532 - val_accuracy: 0.8808\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.9029 - val_loss: 0.4489 - val_accuracy: 0.8817\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4398 - accuracy: 0.8849 - val_loss: 0.4446 - val_accuracy: 0.8833\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8915 - val_loss: 0.4408 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8912 - val_loss: 0.4369 - val_accuracy: 0.8833\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8963 - val_loss: 0.4336 - val_accuracy: 0.8817\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3982 - accuracy: 0.8960 - val_loss: 0.4301 - val_accuracy: 0.8825\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.9012 - val_loss: 0.4273 - val_accuracy: 0.8833\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8938 - val_loss: 0.4238 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8948 - val_loss: 0.4203 - val_accuracy: 0.8817\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8925 - val_loss: 0.4178 - val_accuracy: 0.8850\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3886 - accuracy: 0.8993 - val_loss: 0.4147 - val_accuracy: 0.8850\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3805 - accuracy: 0.9028 - val_loss: 0.4126 - val_accuracy: 0.8867\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.9023 - val_loss: 0.4097 - val_accuracy: 0.8842\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3811 - accuracy: 0.8978 - val_loss: 0.4067 - val_accuracy: 0.8842\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3780 - accuracy: 0.8984 - val_loss: 0.4044 - val_accuracy: 0.8833\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3621 - accuracy: 0.9065 - val_loss: 0.4023 - val_accuracy: 0.8842\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3788 - accuracy: 0.8971 - val_loss: 0.3999 - val_accuracy: 0.8850\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3766 - accuracy: 0.8925 - val_loss: 0.3975 - val_accuracy: 0.8850\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3500 - accuracy: 0.9090 - val_loss: 0.3950 - val_accuracy: 0.8883\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3634 - accuracy: 0.8971 - val_loss: 0.3924 - val_accuracy: 0.8908\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.9010 - val_loss: 0.3904 - val_accuracy: 0.8908\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3575 - accuracy: 0.9077 - val_loss: 0.3884 - val_accuracy: 0.8917\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3578 - accuracy: 0.9068 - val_loss: 0.3870 - val_accuracy: 0.8908\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3669 - accuracy: 0.9013 - val_loss: 0.3849 - val_accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3508 - accuracy: 0.9128 - val_loss: 0.3831 - val_accuracy: 0.8925\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3368 - accuracy: 0.9197 - val_loss: 0.3811 - val_accuracy: 0.8933\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3487 - accuracy: 0.9115 - val_loss: 0.3794 - val_accuracy: 0.8958\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3291 - accuracy: 0.9152 - val_loss: 0.3785 - val_accuracy: 0.8933\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.9167 - val_loss: 0.3766 - val_accuracy: 0.8958\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3268 - accuracy: 0.9160 - val_loss: 0.3748 - val_accuracy: 0.8967\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.9139 - val_loss: 0.3733 - val_accuracy: 0.8958\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3287 - accuracy: 0.9146 - val_loss: 0.3712 - val_accuracy: 0.8967\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.9129 - val_loss: 0.3698 - val_accuracy: 0.8975\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3281 - accuracy: 0.9160 - val_loss: 0.3682 - val_accuracy: 0.8992\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.9114 - val_loss: 0.3671 - val_accuracy: 0.8992\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3226 - accuracy: 0.9149 - val_loss: 0.3655 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3219 - accuracy: 0.9198 - val_loss: 0.3645 - val_accuracy: 0.8992\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3198 - accuracy: 0.9124 - val_loss: 0.3628 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3241 - accuracy: 0.9178 - val_loss: 0.3619 - val_accuracy: 0.8992\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3170 - accuracy: 0.9170 - val_loss: 0.3597 - val_accuracy: 0.9008\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2947 - accuracy: 0.9233 - val_loss: 0.3596 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3096 - accuracy: 0.9227 - val_loss: 0.3585 - val_accuracy: 0.9008\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.9125 - val_loss: 0.3564 - val_accuracy: 0.9008\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3060 - accuracy: 0.9180 - val_loss: 0.3557 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2973 - accuracy: 0.9253 - val_loss: 0.3544 - val_accuracy: 0.9008\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3208 - accuracy: 0.9214 - val_loss: 0.3538 - val_accuracy: 0.9008\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2984 - accuracy: 0.9244 - val_loss: 0.3519 - val_accuracy: 0.8992\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3168 - accuracy: 0.9138 - val_loss: 0.3509 - val_accuracy: 0.9025\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2965 - accuracy: 0.9215 - val_loss: 0.3497 - val_accuracy: 0.9017\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2992 - accuracy: 0.9187 - val_loss: 0.3489 - val_accuracy: 0.9025\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3094 - accuracy: 0.9148 - val_loss: 0.3488 - val_accuracy: 0.9017\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Evaluate the model using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3916839361190796\n",
      "Test accuracy: 0.8840000033378601\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9828491e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9828491e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.994, 0.   ,\n",
       "        0.004]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "# Display the image.\n",
    "plt.imshow(X_test[n])\n",
    "\n",
    "# Model prediction: probability for each class.\n",
    "y_prob = model.predict(np.expand_dims(X_test[n], axis=0))\n",
    "y_prob.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The evaluation score is 88.8%, which is okay but not very impressive. Why? Can we improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and accuracy have evolved over the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9868837e50>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'.-', label='loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy, validation accuracy')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.ylim(0.7,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like the model is still underfitting. We can increase the number of epochs or learning rate, but we can try to use the \"adam\" optimizer which will monitor and adjust the learning rate as the training proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9828418a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9828418a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.7991 - accuracy: 0.7393WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9862babdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9862babdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "150/150 [==============================] - 2s 8ms/step - loss: 0.7913 - accuracy: 0.7419 - val_loss: 0.2878 - val_accuracy: 0.9133\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1911 - accuracy: 0.9351 - val_loss: 0.3327 - val_accuracy: 0.9050\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1077 - accuracy: 0.9717 - val_loss: 0.2736 - val_accuracy: 0.9217\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9820 - val_loss: 0.3035 - val_accuracy: 0.9150\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.2809 - val_accuracy: 0.9317\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.3048 - val_accuracy: 0.9258\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.3563 - val_accuracy: 0.9183\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9823 - val_loss: 0.3305 - val_accuracy: 0.9217\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.2719 - val_accuracy: 0.9475\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.3134 - val_accuracy: 0.9450\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.3155 - val_accuracy: 0.9358\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.2671 - val_accuracy: 0.9492\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.3758 - val_accuracy: 0.9325\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.3821 - val_accuracy: 0.9325\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.5186 - val_accuracy: 0.9275\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0855 - accuracy: 0.9767 - val_loss: 0.3503 - val_accuracy: 0.9292\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.3283 - val_accuracy: 0.9367\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.4343 - val_accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.3731 - val_accuracy: 0.9317\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.4073 - val_accuracy: 0.9233\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9958 - val_loss: 0.3772 - val_accuracy: 0.9358\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3730 - val_accuracy: 0.9400\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.3591 - val_accuracy: 0.9375\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.5535e-04 - accuracy: 0.9996 - val_loss: 0.3452 - val_accuracy: 0.9442\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 5.8045e-05 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9425\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 6.9241e-05 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9425\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.5244e-05 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9425\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.0821e-05 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9417\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 3.1639e-05 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9417\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.1115e-05 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9417\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.4268e-05 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9417\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.1465e-05 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9417\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.7229e-05 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9417\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.6659e-05 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9417\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.6671e-05 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9417\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.4891e-05 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9417\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.1765e-05 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9417\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.0691e-05 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9417\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.0607e-05 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9417\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 9.9078e-06 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9425\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 7.7918e-06 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9433\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 7.4963e-06 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9433\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 7.1473e-06 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9442\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 6.2529e-06 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9442\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.6718e-06 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9450\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.1729e-06 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9450\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.3920e-06 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9442\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 3.6403e-06 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9433\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.2536e-06 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9450\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.3910e-06 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9450\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.4935e-06 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9458\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.3582e-06 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9442\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.1418e-06 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9458\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.9789e-06 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9467\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.8594e-06 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9467\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.4420e-06 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9467\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.2351e-06 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9467\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.1566e-06 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9467\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.2229e-06 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9467\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 9.0063e-07 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9467\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.1580e-07 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.0194e-07 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9475\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.7901e-07 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9467\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 4.8866e-07 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9467\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 4.2472e-07 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 4.2186e-07 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9467\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.8777e-07 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9467\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.6435e-07 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9467\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.9558e-07 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9467\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.9327e-07 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9467\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.7121e-07 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9467\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.5284e-07 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9467\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.5053e-07 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9467\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.4267e-07 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9467\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 9.4835e-08 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9467\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.4999e-08 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9467\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.1987e-07 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9467\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.8870e-08 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9467\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 6.6145e-08 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9467\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.6897e-08 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9467\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.2381e-08 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9467\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.6010e-08 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9467\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 4.8621e-08 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9458\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.1129e-08 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9458\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.0062e-08 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9458\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 4.7515e-08 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9458\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.8880e-08 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9458\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.4623e-08 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.9458\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.2698e-08 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9475\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.0786e-08 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.9475\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 3.0475e-08 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.9475\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.6645e-08 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.9475\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.4455e-08 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9475\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.5235e-08 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.9475\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.3403e-08 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.9483\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.2693e-08 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.9483\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.7668e-08 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9483\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.4074e-08 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.9483\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.5578e-08 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9483\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.6402e-08 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9483\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5405932068824768\n",
      "Test accuracy: 0.9470000267028809\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how loss and accuracy have evolved over the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss, validation loss')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.epoch, history2.history['loss'],'.-', label='loss')\n",
    "plt.plot(history2.epoch, history2.history['val_loss'],'.-', label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss, validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy, validation accuracy')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.epoch, history2.history['accuracy'],'.-', label='accuracy')\n",
    "plt.plot(history2.epoch, history2.history['val_accuracy'],'.-', label='validation accuracy')\n",
    "plt.ylim(0.9,1.01)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy, validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimizer turned out to be extremely efficient! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
